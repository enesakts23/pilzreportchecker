import re
import os
import json
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Any
import PyPDF2
from docx import Document
import pandas as pd
from dataclasses import dataclass, asdict
import logging

# Offline √ßeviri i√ßin Helsinki-NLP modelleri
try:
    from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM
    OFFLINE_TRANSLATION_AVAILABLE = True
except ImportError:
    OFFLINE_TRANSLATION_AVAILABLE = False
    print("‚ö†Ô∏è Offline √ßeviri desteƒüi i√ßin: pip install transformers torch sentencepiece")

# Dil tespiti i√ßin
try:
    from langdetect import detect
    LANGUAGE_DETECTION_AVAILABLE = True
except ImportError:
    LANGUAGE_DETECTION_AVAILABLE = False
    print("‚ö†Ô∏è Dil tespiti i√ßin: pip install langdetect")

# Logging konfig√ºrasyonu
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class GroundingContinuityCriteria:
    """Topraklama S√ºreklilik rapor kriterleri veri sƒ±nƒ±fƒ±"""
    genel_rapor_bilgileri: Dict[str, Any]
    olcum_metodu_standart_referanslari: Dict[str, Any]
    olcum_sonuc_tablosu: Dict[str, Any]
    uygunluk_degerlendirmesi: Dict[str, Any]
    gorsel_teknik_dokumantasyon: Dict[str, Any]
    sonuc_oneriler: Dict[str, Any]

@dataclass
class GroundingAnalysisResult:
    """Topraklama S√ºreklilik analiz son    if status == "FAIL":
        print("### üö´ GE√áEMEMENƒ∞N NEDENLERƒ∞:")
        print(f"1. **Ge√ßme sƒ±nƒ±rƒ±:** 70 puan, **Alƒ±nan:** {total_score} puan")
        
        # Tarih kontrol√º
        if not report['tarih_gecerliligi']['gecerli']:
            print("2. **KRƒ∞Tƒ∞K:** √ñl√ß√ºm tarihi ile rapor tarihi arasƒ±ndaki fark 1 yƒ±ldan fazla")
        
        print("3. Kritik eksiklikler:")
        
        for category in categories:
            cat_name = category[0]
            if cat_name in report['puanlama']['category_scores']:
                score_data = report['puanlama']['category_scores'][cat_name]
                if score_data['percentage'] < 50:
                    print(f"   - {cat_name} yetersiz")
        
        uygunsuz_count = len(report['cikarilan_degerler'].get('uygunsuz_olcumler', []))
        if uygunsuz_count > 0:
            print(f"   - {uygunsuz_count} nokta uygunsuzluk var ve √ß√∂z√ºm √∂nerisi yok")"""
    criteria_name: str
    found: bool
    content: str
    score: int
    max_score: int
    details: Dict[str, Any]

class GroundingContinuityReportAnalyzer:
    """Topraklama S√ºreklilik rapor analiz sƒ±nƒ±fƒ±"""
    
    def __init__(self):
        # Offline √ßeviri modellerini ba≈ülat
        self.translation_models = {}
        self.language_detector = None
        
        if OFFLINE_TRANSLATION_AVAILABLE and LANGUAGE_DETECTION_AVAILABLE:
            self.init_translation_models()
        
        self.criteria_weights = {
            "Genel Rapor Bilgileri": 15,
            "√ñl√ß√ºm Metodu ve Standart Referanslarƒ±": 15,
            "√ñl√ß√ºm Sonu√ß Tablosu": 25,
            "Uygunluk Deƒüerlendirmesi": 20,
            "G√∂rsel ve Teknik D√∂k√ºmantasyon": 10,
            "Sonu√ß ve √ñneriler": 15
        }
        
        self.criteria_details = {
            "Genel Rapor Bilgileri": {
                "proje_adi_numarasi": {"pattern": r"(?:Project\s*(?:Name|No)|Proje\s*(?:Ad[ƒ±i]|No)|Report\s*Title|Document\s*Title|E\d{2}\.\d{3}|C\d{2}\.\d{3}|T\d{2,3}[-.]?\d{3,4})", "weight": 3},
                "olcum_tarihi": {"pattern": r"(?:Measurement\s*Date|√ñl√ß√ºm\s*Tarihi|Test\s*Date|Date\s*of\s*(?:Test|Measurement)|Measured\s*on|Tested\s*on|\d{1,2}[./\-]\d{1,2}[./\-]\d{4})", "weight": 3},
                "rapor_tarihi": {"pattern": r"(?:Report\s*Date|Rapor\s*Tarihi|Issue\s*Date|Document\s*Date|Prepared\s*on|Created\s*on|Date|Tarih|\d{1,2}[./\-]\d{1,2}[./\-]\d{4})", "weight": 3},
                "tesis_bolge_hat": {"pattern": r"(?:Customer|M√º≈üteri|Client|Facility|Tesis|Plant|Factory|Company|Firma|Toyota|DANONE|Ford|BOSCH)", "weight": 2},
                "rapor_numarasi": {"pattern": r"(?:Report\s*No|Rapor\s*No|Document\s*No|Belge\s*No|E\d{2}\.\d{3}|C\d{2}\.\d{3}|SM\s*\d+|MCC\d+)", "weight": 2},
                "revizyon": {"pattern": r"(?:Version|Revizyon|Rev\.?|v)\s*[:=]?\s*(\d+|[A-Z])", "weight": 1},
                "firma_personel": {"pattern": r"(?:Prepared\s*by|Hazƒ±rlayan|Performed\s*by|√ñl√ß√ºm√º\s*Yapan|Consultant|Engineer|PILZ)", "weight": 1}
            },
            "√ñl√ß√ºm Metodu ve Standart Referanslarƒ±": {
                "olcum_cihazi": {"pattern": r"(?:Measuring\s*Instrument|√ñl√ß√ºm\s*Cihaz[ƒ±i]|Test\s*Equipment|Multimeter|Multimetre|Ohmmeter|Instrument|Equipment|Device|Tester|Fluke|Metrix|Chauvin|Megger|Hioki)", "weight": 6},
                "kalibrasyon": {"pattern": r"(?:Calibration|Kalibrasyon|Kalibre|Certificate|Sertifika|Cal\s*Date)", "weight": 4},
                "standartlar": {"pattern": r"(?:EN\s*60204[-\s]*1?|IEC\s*60364|Standard|Standart)", "weight": 5}
            },
            "√ñl√ß√ºm Sonu√ß Tablosu": {
                "sira_numarasi": {"pattern": r"(?:S[ƒ±i]ra\s*(?:No|Numaras[ƒ±i])|^\s*\d+\s)", "weight": 3},
                "makine_hat_bolge": {"pattern": r"(?:8X45|8X50|8X9J|9J73|8X52|8X60|8X62|8X70)\s*(?:R[1-9])?\s*(?:Hatt[ƒ±i]|Line|Zone|B√∂lge)", "weight": 3},
                "olcum_noktasi": {"pattern": r"(?:Robot\s*\d+\.\s*Eksen\s*Motoru|Kalemtra≈ü|Lift\s*and\s*Shift|Motor|Ekipman|Equipment|Device)", "weight": 3},
                "rlo_degeri": {"pattern": r"(\d+[.,]?\d*)\s*(?:mŒ©|mohm|ohm|Œ©)", "weight": 5},
                "yuk_iletken_kesiti": {"pattern": r"(?:4x4|4x2[.,]5|4x6|4x10|Y√ºk\s*ƒ∞letken|Load\s*Conductor|PE\s*ƒ∞letken|PE\s*Conductor)", "weight": 4},
                "referans_degeri": {"pattern": r"(?:500\s*mŒ©|500\s*ohm|500\s*Œ©|EN\s*60204|IEC\s*60364)", "weight": 3},
                "uygunluk_durumu": {"pattern": r"(?:UYGUN|OK|PASS|Compliant|Uygun)", "weight": 4},
                "kesit_uygunlugu": {"pattern": r"(?:UYGUN|OK|PASS|Compliant|Uygun)", "weight": 3}
            },
            "Uygunluk Deƒüerlendirmesi": {
                "toplam_olcum_nokta": {"pattern": r"(?:222|220|200|Toplam.*\d+)", "weight": 5},
                "uygun_nokta_sayisi": {"pattern": r"(?:211|210|UYGUN)", "weight": 5},
                "uygunsuz_isaretleme": {"pattern": r"\*D\.Y", "weight": 5, "reverse_logic": True},  # Uygunsuzluk bulunmazsa tam puan
                "standart_referans_uygunluk": {"pattern": r"(?:500\s*mŒ©|EN\s*60204)", "weight": 5}
            },
            "G√∂rsel ve Teknik D√∂k√ºmantasyon": {
                "cihaz_baglanti_fotografi": {"pattern": r"(?:Cihaz.*Fotoƒüraf|Baƒülant[ƒ±i].*Fotoƒüraf|√ñl√ß√ºm.*Cihaz|Photo|Image|Figure|Resim|G√∂rsel)", "weight": 10}
            },
            "Sonu√ß ve √ñneriler": {
                "genel_uygunluk": {"pattern": r"(?:Genel\s*Uygunluk|Sonu√ß|UYGUN|UYGUNSUZ|Result|Conclusion|Compliant|Non-compliant)", "weight": 8},
                "standart_atif": {"pattern": r"(?:EN\s*60204|IEC\s*60364|Standart.*Atƒ±f|Standart.*Referans|Standard.*Reference)", "weight": 7}
            }
        }
    
    def init_translation_models(self):
        """Offline √ßeviri modellerini ba≈ülat"""
        try:
            logger.info("Offline √ßeviri modelleri y√ºkleniyor...")
            
            # En yaygƒ±n diller i√ßin Helsinki-NLP modelleri
            model_mapping = {
                'en': 'Helsinki-NLP/opus-mt-en-tr',  # ƒ∞ngilizce -> T√ºrk√ße
                'de': 'Helsinki-NLP/opus-mt-de-tr',  # Almanca -> T√ºrk√ße
                'fr': 'Helsinki-NLP/opus-mt-fr-tr',  # Fransƒ±zca -> T√ºrk√ße
                'es': 'Helsinki-NLP/opus-mt-es-tr',  # ƒ∞spanyolca -> T√ºrk√ße
                'it': 'Helsinki-NLP/opus-mt-it-tr',  # ƒ∞talyanca -> T√ºrk√ße
            }
            
            for lang_code, model_name in model_mapping.items():
                try:
                    # Model varsa y√ºkle, yoksa atla
                    tokenizer = AutoTokenizer.from_pretrained(model_name)
                    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
                    
                    self.translation_models[lang_code] = {
                        'tokenizer': tokenizer,
                        'model': model,
                        'pipeline': pipeline('translation', 
                                           model=model, 
                                           tokenizer=tokenizer,
                                           device=-1)  # CPU kullan
                    }
                    logger.info(f"‚úÖ {lang_code.upper()} -> TR modeli y√ºklendi")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è {lang_code.upper()} -> TR modeli y√ºklenemedi: {e}")
                    
            logger.info(f"Toplam {len(self.translation_models)} √ßeviri modeli hazƒ±r")
            
        except Exception as e:
            logger.error(f"√áeviri modelleri ba≈ülatƒ±lamadƒ±: {e}")
    
    def detect_language(self, text: str) -> str:
        """Metin dilini tespit et"""
        if not LANGUAGE_DETECTION_AVAILABLE:
            return 'tr'
        
        try:
            # Sadece ilk 500 karakterle dil tespiti (hƒ±z i√ßin)
            sample_text = text[:500].strip()
            if not sample_text:
                return 'tr'
                
            detected_lang = detect(sample_text)
            logger.info(f"Tespit edilen dil: {detected_lang}")
            return detected_lang
            
        except Exception as e:
            logger.warning(f"Dil tespiti ba≈üarƒ±sƒ±z: {e}")
            return 'tr'
    
    def translate_to_turkish(self, text: str, source_lang: str) -> str:
        """Metni T√ºrk√ße'ye √ßevir"""
        if source_lang == 'tr' or source_lang not in self.translation_models:
            return text
        
        try:
            model_info = self.translation_models[source_lang]
            pipeline_translator = model_info['pipeline']
            
            logger.info(f"Metin {source_lang.upper()} -> TR √ßevriliyor...")
            
            # Uzun metinleri par√ßalara b√∂l
            max_length = 512  # Transformer model limiti
            text_chunks = []
            
            # Metni c√ºmlelere b√∂l
            sentences = re.split(r'[.!?]+', text)
            
            current_chunk = ""
            for sentence in sentences:
                if len(current_chunk + sentence) < max_length:
                    current_chunk += sentence + ". "
                else:
                    if current_chunk:
                        text_chunks.append(current_chunk.strip())
                    current_chunk = sentence + ". "
            
            if current_chunk:
                text_chunks.append(current_chunk.strip())
            
            # Her par√ßayƒ± √ßevir
            translated_chunks = []
            for i, chunk in enumerate(text_chunks):
                if not chunk.strip():
                    continue
                    
                try:
                    result = pipeline_translator(chunk)
                    if isinstance(result, list) and len(result) > 0:
                        translated_text = result[0]['translation_text']
                    else:
                        translated_text = str(result)
                    
                    translated_chunks.append(translated_text)
                    
                    if i % 10 == 0:  # Her 10 par√ßada progress g√∂ster
                        logger.info(f"√áeviri ilerlemesi: {i+1}/{len(text_chunks)}")
                        
                except Exception as chunk_error:
                    logger.warning(f"Par√ßa √ßevirisi ba≈üarƒ±sƒ±z: {chunk_error}")
                    translated_chunks.append(chunk)  # √áeviremezse orijinali kullan
            
            final_text = ' '.join(translated_chunks)
            logger.info("‚úÖ √áeviri tamamlandƒ±")
            return final_text
            
        except Exception as e:
            logger.error(f"√áeviri hatasƒ±: {e}")
            return text  # Hata durumunda orijinal metni d√∂nd√ºr
    
    def get_language_name(self, lang_code: str) -> str:
        """Dil kodunu dil adƒ±na √ßevir"""
        lang_names = {
            'tr': 'T√ºrk√ße',
            'en': 'ƒ∞ngilizce', 
            'de': 'Almanca',
            'fr': 'Fransƒ±zca',
            'es': 'ƒ∞spanyolca',
            'it': 'ƒ∞talyanca',
            'pt': 'Portekizce',
            'ru': 'Rus√ßa',
            'zh': '√áince',
            'ja': 'Japonca',
            'ko': 'Korece',
            'ar': 'Arap√ßa'
        }
        return lang_names.get(lang_code, f'Bilinmeyen ({lang_code})')

    def extract_text_from_pdf(self, pdf_path: str) -> str:
        """PDF'den metin √ßƒ±karma"""
        try:
            with open(pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                text = ""
                for page in pdf_reader.pages:
                    text += page.extract_text() + "\n"
                return text
        except Exception as e:
            logger.error(f"PDF okuma hatasƒ±: {e}")
            return ""
    
    def extract_text_from_docx(self, docx_path: str) -> str:
        """DOCX'den metin √ßƒ±karma"""
        try:
            doc = Document(docx_path)
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            # Tablolarƒ± da kontrol et
            for table in doc.tables:
                for row in table.rows:
                    for cell in row.cells:
                        text += cell.text + "\t"
                    text += "\n"
            return text
        except Exception as e:
            logger.error(f"DOCX okuma hatasƒ±: {e}")
            return ""
    
    def extract_text_from_excel(self, excel_path: str) -> str:
        """Excel'den metin √ßƒ±karma"""
        try:
            # T√ºm sheet'leri oku
            xls = pd.ExcelFile(excel_path)
            text = ""
            for sheet_name in xls.sheet_names:
                df = pd.read_excel(excel_path, sheet_name=sheet_name)
                # DataFrame'i string'e √ßevir
                text += f"Sheet: {sheet_name}\n"
                text += df.to_string() + "\n\n"
            return text
        except Exception as e:
            logger.error(f"Excel okuma hatasƒ±: {e}")
            return ""
    
    def get_file_text(self, file_path: str) -> Tuple[str, str]:
        """Dosya tipine g√∂re metin √ßƒ±karma ve √ßeviri"""
        file_extension = os.path.splitext(file_path)[1].lower()
        
        # √ñnce metni √ßƒ±kar
        original_text = ""
        if file_extension == '.pdf':
            original_text = self.extract_text_from_pdf(file_path)
        elif file_extension in ['.docx', '.doc']:
            original_text = self.extract_text_from_docx(file_path)
        elif file_extension in ['.xlsx', '.xls']:
            original_text = self.extract_text_from_excel(file_path)
        else:
            logger.warning(f"Desteklenmeyen dosya tipi: {file_extension}")
            return "", "unknown"
        
        if not original_text:
            return "", "unknown"
        
        # Dil tespiti
        detected_lang = self.detect_language(original_text)
        
        # √áeviri (gerekirse)
        if detected_lang != 'tr' and len(self.translation_models) > 0:
            translated_text = self.translate_to_turkish(original_text, detected_lang)
            return translated_text, detected_lang
        else:
            return original_text, detected_lang
    
    def normalize_date_string(self, date_str: str) -> str:
        """Tarih string'ini DD/MM/YYYY formatƒ±na √ßevir"""
        if not date_str or date_str == "Bulunamadƒ±":
            return date_str
            
        # Ay isimleri √ßeviri tablosu
        month_names = {
            # ƒ∞ngilizce ay isimleri
            'jan': '01', 'january': '01',
            'feb': '02', 'february': '02', 
            'mar': '03', 'march': '03',
            'apr': '04', 'april': '04',
            'may': '05',
            'jun': '06', 'june': '06',
            'jul': '07', 'july': '07',
            'aug': '08', 'august': '08',
            'sep': '09', 'september': '09',
            'oct': '10', 'october': '10',
            'nov': '11', 'november': '11',
            'dec': '12', 'december': '12',
            
            # T√ºrk√ße ay isimleri
            'ocak': '01',
            '≈üubat': '02', 'subat': '02',
            'mart': '03',
            'nisan': '04',
            'mayƒ±s': '05', 'mayis': '05',
            'haziran': '06',
            'temmuz': '07',
            'aƒüustos': '08', 'agustos': '08',
            'eyl√ºl': '09', 'eylul': '09',
            'ekim': '10',
            'kasƒ±m': '11', 'kasim': '11',
            'aralƒ±k': '12', 'aralik': '12'
        }
        
        # √áe≈üitli tarih formatlarƒ±nƒ± normalize et
        date_str = date_str.strip()
        
        # DD/MM/YYYY veya DD.MM.YYYY veya DD-MM-YYYY formatlarƒ±
        if re.match(r'\d{1,2}[./\-]\d{1,2}[./\-]\d{4}', date_str):
            return date_str.replace('.', '/').replace('-', '/')
        
        # YYYY/MM/DD formatƒ±
        if re.match(r'\d{4}[./\-]\d{1,2}[./\-]\d{1,2}', date_str):
            parts = re.split(r'[./\-]', date_str)
            return f"{parts[2].zfill(2)}/{parts[1].zfill(2)}/{parts[0]}"
        
        # DD Month YYYY formatƒ± (√∂rn: "18 Apr 2023" veya "18 Nisan 2023")
        month_pattern = r'(\d{1,2})\s+([a-zA-Zƒüƒ±√º≈ü√ß√∂ƒûI√ú≈û√á√ñ]+)\s+(\d{4})'
        match = re.match(month_pattern, date_str, re.IGNORECASE)
        if match:
            day, month_name, year = match.groups()
            month_name_lower = month_name.lower()
            if month_name_lower in month_names:
                month_num = month_names[month_name_lower]
                return f"{day.zfill(2)}/{month_num}/{year}"
        
        # Eƒüer hi√ßbir format e≈üle≈ümezse orijinal string'i d√∂nd√ºr
        return date_str.replace('.', '/').replace('-', '/')
    
    def check_date_validity(self, text: str, file_path: str = None) -> Tuple[bool, str, str, str]:
        """1 yƒ±l kuralƒ± - √ñl√ß√ºm tarihi ile rapor tarihi arasƒ±ndaki fark kontrol√º"""
        
        # √ñl√ß√ºm tarihi arama - √ßok kapsamlƒ± pattern'lar
        olcum_patterns = [
            # T√ºrk√ße formatlar
            r"(?:√ñl√ß√ºm\s*Tarihi|Test\s*Tarihi|√ñl√ß√ºm\s*Yapƒ±ldƒ±ƒüƒ±\s*Tarih)\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
            r"(?:√ñl√ß√ºm|Test).*?(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
            r"(\d{1,2}[./\-]\d{1,2}[./\-]\d{4}).*?(?:√∂l√ß√ºm|test)",
            
            # ƒ∞ngilizce formatlar
            r"(?:Measurement\s*Date|Test\s*Date|Date\s*of\s*(?:Test|Measurement))\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
            r"(?:Measured\s*on|Tested\s*on)\s*[:=]?\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
            r"(\d{1,2}[./\-]\d{1,2}[./\-]\d{4}).*?(?:measurement|test)",
            
            # Genel formatlar
            r"(\d{4}[./\-]\d{1,2}[./\-]\d{1,2})",  # YYYY/MM/DD
            r"(\d{1,2}\s+(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+\d{4})",
            r"(\d{1,2}\s+(?:Ocak|≈ûubat|Mart|Nisan|Mayƒ±s|Haziran|Temmuz|Aƒüustos|Eyl√ºl|Ekim|Kasƒ±m|Aralƒ±k)\s+\d{4})"
        ]
        
        # Rapor tarihi arama - √ßok kapsamlƒ± pattern'lar
        rapor_patterns = [
            # T√ºrk√ße formatlar
            r"(?:Rapor\s*Tarihi|Belge\s*Tarihi|Hazƒ±rlanma\s*Tarihi)\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
            r"(?:Rapor|Belge).*?(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
            r"(?:Hazƒ±rlayan|Hazƒ±rlandƒ±)\s*[:=]?\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
            
            # ƒ∞ngilizce formatlar
            r"(?:Report\s*Date|Document\s*Date|Issue\s*Date|Prepared\s*Date)\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
            r"(?:Prepared\s*on|Issued\s*on|Created\s*on)\s*[:=]?\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
            
            # Genel formatlar
            r"(?:Date|Tarih)\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
            r"(\d{4}[./\-]\d{1,2}[./\-]\d{1,2})",  # YYYY/MM/DD
            r"(\d{1,2}\s+(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+\d{4})",
            r"(\d{1,2}\s+(?:Ocak|≈ûubat|Mart|Nisan|Mayƒ±s|Haziran|Temmuz|Aƒüustos|Eyl√ºl|Ekim|Kasƒ±m|Aralƒ±k)\s+\d{4})"
        ]
        
        olcum_tarihi = None
        rapor_tarihi = None
        
        # √ñl√ß√ºm tarihini bul
        for pattern in olcum_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                olcum_tarihi = matches[0]
                break
        
        # Rapor tarihini bul
        for pattern in rapor_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                rapor_tarihi = matches[0]
                break
        
        # Eƒüer tarihler bulunamazsa dosya modifikasyon tarihini kullan
        if not rapor_tarihi and file_path and os.path.exists(file_path):
            file_mod_time = datetime.fromtimestamp(os.path.getmtime(file_path))
            rapor_tarihi = file_mod_time.strftime("%d/%m/%Y")
        elif not rapor_tarihi:
            rapor_tarihi = datetime.now().strftime("%d/%m/%Y")
        
        try:
            if olcum_tarihi:
                # Tarih formatlarƒ±nƒ± normalize et ve ay isimlerini √ßevir
                olcum_tarihi_clean = self.normalize_date_string(olcum_tarihi)
                rapor_tarihi_clean = self.normalize_date_string(rapor_tarihi)
                
                olcum_date = datetime.strptime(olcum_tarihi_clean, '%d/%m/%Y')
                rapor_date = datetime.strptime(rapor_tarihi_clean, '%d/%m/%Y')
                
                # Tarih farkƒ±nƒ± hesapla
                tarih_farki = (rapor_date - olcum_date).days
                
                # 1 yƒ±l (365 g√ºn) kontrol√º
                is_valid = tarih_farki <= 365
                
                status_message = f"√ñl√ß√ºm: {olcum_tarihi_clean}, Rapor: {rapor_tarihi_clean}, Fark: {tarih_farki} g√ºn"
                if is_valid:
                    status_message += " (GE√áERLƒ∞)"
                else:
                    status_message += " (GE√áERSƒ∞Z - 1 yƒ±ldan fazla)"
                
                return is_valid, olcum_tarihi_clean, rapor_tarihi_clean, status_message
            else:
                return False, "Bulunamadƒ±", rapor_tarihi, "√ñl√ß√ºm tarihi bulunamadƒ± - RAPOR GE√áERSƒ∞Z"
                
        except ValueError as e:
            logger.error(f"Tarih parse hatasƒ±: {e}")
            return False, olcum_tarihi or "Bulunamadƒ±", rapor_tarihi, f"Tarih formatƒ± hatasƒ±: {e}"
    
    def analyze_criteria(self, text: str, category: str) -> Dict[str, GroundingAnalysisResult]:
        """Belirli kategori kriterlerini analiz etme"""
        results = {}
        criteria = self.criteria_details.get(category, {})
        
        for criterion_name, criterion_data in criteria.items():
            pattern = criterion_data["pattern"]
            weight = criterion_data["weight"]
            reverse_logic = criterion_data.get("reverse_logic", False)
            
            matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)
            
            if matches:
                if reverse_logic:
                    # Uygunsuzluk bulundu - d√º≈ü√ºk puan
                    content = f"Uygunsuzluk tespit edildi: {str(matches[:3])}"
                    found = True
                    score = weight // 3  # D√º≈ü√ºk puan
                else:
                    content = str(matches[0]) if len(matches) == 1 else str(matches)
                    found = True
                    score = weight
            else:
                if reverse_logic:
                    # Uygunsuzluk bulunamadƒ± - tam puan (iyi bir ≈üey)
                    content = "Uygunsuzluk bulunamadƒ± - T√ºm √∂l√ß√ºmler uygun"
                    found = True
                    score = weight  # Tam puan
                else:
                    # ƒ∞kincil arama - daha genel pattern
                    general_patterns = {
                        "proje_adi_numarasi": r"(C\d+\.\d+|Proje|Project|SM\s*\d+)",
                        "tesis_bolge_hat": r"(Tesis|Makine|Hat|B√∂lge|Line)",
                        "olcum_cihazi": r"(Multimetre|Ohmmetre|√ñl√ß√ºm|Cihaz)",
                        "kalibrasyon": r"(Kalibrasyon|Kalibre|Cert|Sertifika)",
                        "standartlar": r"(EN\s*60204|IEC\s*60364|Standard|Standart)",
                        "rlo_degeri": r"(\d+[.,]?\d*\s*(?:mŒ©|mohm|ohm))",
                        "uygunluk_durumu": r"(UYGUN|OK|NOK|Uygun|Deƒüil)",
                        "risk_belirtme": r"(Risk|Tehlike|Uygunsuz|Problem)",
                        "genel_uygunluk": r"(Sonu√ß|Result|Uygun|Ge√ßer|Pass|Fail)"
                    }
                    
                    general_pattern = general_patterns.get(criterion_name)
                    if general_pattern:
                        general_matches = re.findall(general_pattern, text, re.IGNORECASE)
                        if general_matches:
                            content = f"Genel e≈üle≈üme bulundu: {general_matches[0]}"
                            found = True
                            score = weight // 2  # Kƒ±smi puan
                        else:
                            content = "Bulunamadƒ±"
                            found = False
                            score = 0
                    else:
                        content = "Bulunamadƒ±"
                        found = False
                        score = 0
            
            results[criterion_name] = GroundingAnalysisResult(
                criteria_name=criterion_name,
                found=found,
                content=content,
                score=score,
                max_score=weight,
                details={"pattern_used": pattern, "matches_found": len(matches) if matches else 0}
            )
        
        return results
    
    def extract_specific_values(self, text: str, file_path: str = None) -> Dict[str, Any]:
        """Spesifik deƒüerleri √ßƒ±karma - Dosya adƒ±ndan da bilgi √ßƒ±kar"""
        values = {}
        
        # √ñnce dosya adƒ±ndan bilgileri √ßƒ±kar
        if file_path:
            filename = os.path.basename(file_path)
            
            # Proje numarasƒ± pattern'leri - farklƒ± formatlar i√ßin
            proje_patterns = [
                r'(C\d{2}\.\d{3})',  # C20.140 formatƒ±
                r'(E\d{2}\.\d{3})',  # E21.207 formatƒ±
                r'(T\d{2,3}[-\.]?\d{3,4})',  # T21-MCC1201 formatƒ±
                r'(\d{4,6})',        # 20092 gibi sayƒ± formatƒ±
                r'([A-Z]\d{2,3}[.-]\d{3,4})'  # Genel format
            ]
            
            # Rapor numarasƒ± pattern'leri
            rapor_patterns = [
                r'SM\s*(\d+)',
                r'MCC(\d+)',
                r'Report\s*No[\s:]*([A-Z0-9.-]+)',
                r'Rapor[\s:]*([A-Z0-9.-]+)'
            ]
            
            # M√º≈üteri/firma bilgisi
            musteri_patterns = [
                r'Toyota',
                r'DANONE',
                r'Ford',
                r'BOSCH',
                r'P&G'
            ]
            
            # Dosya adƒ±ndan proje no √ßƒ±kar
            proje_no = "Bulunamadƒ±"
            for pattern in proje_patterns:
                match = re.search(pattern, filename, re.IGNORECASE)
                if match:
                    proje_no = match.group(1)
                    break
            values["proje_no"] = proje_no
            
            # Dosya adƒ±ndan rapor numarasƒ± √ßƒ±kar
            rapor_no = "Bulunamadƒ±"
            for pattern in rapor_patterns:
                match = re.search(pattern, filename, re.IGNORECASE)
                if match:
                    rapor_no = match.group(1)
                    break
            values["rapor_numarasi"] = rapor_no
            
            # M√º≈üteri bilgisi
            musteri = "Bulunamadƒ±"
            for pattern in musteri_patterns:
                if re.search(pattern, filename, re.IGNORECASE):
                    musteri = pattern
                    break
            values["musteri"] = musteri
            
            # Revizyon bilgisi
            revizyon_match = re.search(r'[vV](\d+)', filename)
            values["revizyon"] = f"v{revizyon_match.group(1)}" if revizyon_match else "v0"
        
        # √ñnemli deƒüerler i√ßin pattern'ler - √ßok daha kapsamlƒ±
        value_patterns = {
            # Proje adƒ±/numarasƒ± i√ßin kapsamlƒ± pattern'ler
            "proje_adi": [
                r"(?:Project\s*Name|Proje\s*Ad[ƒ±i])\s*[:=]\s*([^\n\r]+)",
                r"(?:Project\s*No|Proje\s*No|Project\s*Number)\s*[:=]\s*([A-Z0-9.-]+)",
                r"(?:Report\s*Title|Rapor\s*Ba≈ül[ƒ±i]ƒü[ƒ±i])\s*[:=]\s*([^\n\r]+)",
                r"(?:Document\s*Title|Belge\s*Ba≈ül[ƒ±i]ƒü[ƒ±i])\s*[:=]\s*([^\n\r]+)",
                r"(LVD\s+[√ñ√∂]l√ß[√ºu]m[^,\n]*)",
                r"(Topraklama\s+S[√ºu]reklilik[^,\n]*)",
                r"(Grounding\s+Continuity[^,\n]*)",
                r"([A-Z][a-z]+\s*-\s*[A-Z][a-z]+.*?[√ñ√∂]l√ß[√ºu]m)",
                r"(E\d{2}\.\d{3}\s*-[^,\n]+)"
            ],
            
            # Rapor numarasƒ± i√ßin kapsamlƒ± pattern'ler
            "rapor_numarasi": [
                r"(?:Report\s*No|Rapor\s*No|Report\s*Number)\s*[:=]\s*([A-Z0-9.-]+)",
                r"(?:Document\s*No|Belge\s*No)\s*[:=]\s*([A-Z0-9.-]+)",
                r"(E\d{2}\.\d{3})",
                r"(C\d{2}\.\d{3})",
                r"(T\d{2,3}[-.]?\d{3,4})",
                r"SM\s*(\d+)",
                r"MCC(\d+)",
                r"^\s*([A-Z]\d{2,3}[.-]\d{3,4})"
            ],
            
            # √ñl√ß√ºm cihazƒ± i√ßin √ßok kapsamlƒ± pattern'ler
            "olcum_cihazi": [
                r"(?:Measuring\s*Instrument|√ñl√ß√ºm\s*Cihaz[ƒ±i]|Test\s*Equipment)\s*[:=]\s*([^\n\r]+)",
                r"(?:Multimeter|Multimetre|Ohmmeter|Ohmmetre)\s*[:=]?\s*([A-Z0-9\s.-]+)",
                r"(?:Instrument|Cihaz)\s*[:=]\s*([^\n\r]+)",
                r"(?:Equipment|Ekipman)\s*[:=]\s*([^\n\r]+)",
                r"(?:Device|Alet)\s*[:=]\s*([^\n\r]+)",
                r"(?:Tester|Test\s*Cihaz[ƒ±i])\s*[:=]?\s*([A-Z0-9\s.-]+)",
                r"(Fluke\s*\d+[A-Z]*)",
                r"(Metrix\s*[A-Z0-9]+)",
                r"(Chauvin\s*Arnoux\s*[A-Z0-9]+)",
                r"(Megger\s*[A-Z0-9]+)",
                r"(Hioki\s*[A-Z0-9]+)",
                r"([A-Z][a-z]+\s*\d+[A-Z]*)",  # Genel marka model formatƒ±
                r"(MŒ©\s*metre|mŒ©\s*metre|Loop\s*Tester|Continuity\s*Tester)"
            ],
            
            # Tesis/m√º≈üteri bilgisi
            "tesis_adi": [
                r"(?:Customer|M√º≈üteri|Client)\s*[:=]\s*([^\n\r]+)",
                r"(?:Facility|Tesis|Plant|Factory)\s*[:=]\s*([^\n\r]+)",
                r"(?:Company|Firma|Corporation)\s*[:=]\s*([^\n\r]+)",
                r"(Toyota[^\n\r]*)",
                r"(DANONE[^\n\r]*)",
                r"(Ford[^\n\r]*)",
                r"(BOSCH[^\n\r]*)",
                r"(?:8X45|8X50|8X9J|9J73)\s*(?:R1|R2|R3)?\s*Hatt[ƒ±i]",
                r"([A-Z][a-z]+\s+[A-Z][a-z]+\s+(?:Factory|Plant|Facility))"
            ],
            

            
            # Firma/personel bilgisi
            "firma_personel": [
                r"(?:Prepared\s*by|Hazƒ±rlayan|Consultant)\s*[:=]\s*([^\n\r]+)",
                r"(?:Performed\s*by|√ñl√ß√ºm√º\s*Yapan)\s*[:=]\s*([^\n\r]+)",
                r"(?:Company|Firma)\s*[:=]\s*([^\n\r]+)",
                r"(?:Engineer|M√ºhendis)\s*[:=]\s*([^\n\r]+)",
                r"(PILZ[^\n\r]*)",
                r"([A-Z][a-z]+\s+[A-Z][a-z]+\s+(?:Engineering|M√ºhendislik))"
            ],
            
            # Tarih pattern'leri - √ßok kapsamlƒ±
            "olcum_tarihi": [
                # T√ºrk√ße formatlar
                r"(?:√ñl√ß√ºm\s*Tarihi|Test\s*Tarihi|√ñl√ß√ºm\s*Yapƒ±ldƒ±ƒüƒ±\s*Tarih)\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                r"(?:√ñl√ß√ºm|Test).*?(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                r"Tarih\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                
                # ƒ∞ngilizce formatlar
                r"(?:Measurement\s*Date|Test\s*Date|Date\s*of\s*(?:Test|Measurement))\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                r"(?:Measured\s*on|Tested\s*on)\s*[:=]?\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                r"(?:Date|When)\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                
                # √áe≈üitli formatlar
                r"(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})\s*(?:tarihinde|on|at|de)",
                r"(\d{4}[./\-]\d{1,2}[./\-]\d{1,2})",  # YYYY/MM/DD formatƒ±
                r"(\d{1,2}\s+(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+\d{4})",  # ƒ∞ngilizce ay isimleri
                r"(\d{1,2}\s+(?:Ocak|≈ûubat|Mart|Nisan|Mayƒ±s|Haziran|Temmuz|Aƒüustos|Eyl√ºl|Ekim|Kasƒ±m|Aralƒ±k)\s+\d{4})",  # T√ºrk√ße ay isimleri
                
                # Tablo i√ßindeki tarihler
                r"(?:Measurement|√ñl√ß√ºm).*?(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                r"(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",  # Genel tarih formatƒ±
            ],
            
            "rapor_tarihi": [
                # T√ºrk√ße formatlar
                r"(?:Rapor\s*Tarihi|Belge\s*Tarihi|Hazƒ±rlanma\s*Tarihi)\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                r"(?:Rapor|Belge).*?(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                r"(?:Hazƒ±rlayan|Hazƒ±rlandƒ±)\s*[:=]?\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                
                # ƒ∞ngilizce formatlar  
                r"(?:Report\s*Date|Document\s*Date|Issue\s*Date|Prepared\s*Date)\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                r"(?:Prepared\s*on|Issued\s*on|Created\s*on)\s*[:=]?\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                r"(?:Report|Document).*?(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                
                # √áe≈üitli formatlar
                r"(?:Date|Tarih)\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                r"(\d{4}[./\-]\d{1,2}[./\-]\d{1,2})",  # YYYY/MM/DD formatƒ±
                r"(\d{1,2}\s+(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+\d{4})",  # ƒ∞ngilizce ay isimleri
                r"(\d{1,2}\s+(?:Ocak|≈ûubat|Mart|Nisan|Mayƒ±s|Haziran|Temmuz|Aƒüustos|Eyl√ºl|Ekim|Kasƒ±m|Aralƒ±k)\s+\d{4})",  # T√ºrk√ße ay isimleri
                
                # Tablo ba≈ülƒ±ƒüƒ± veya footer'daki tarihler
                r"(?:Created|Issued|Published)\s*[:=]?\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                r"(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",  # Genel tarih formatƒ±
            ]
        }
        
        # Metinden deƒüerleri √ßƒ±kar - her pattern listesi i√ßin
        for key, pattern_list in value_patterns.items():
            if key not in values:  # Dosya adƒ±ndan √ßƒ±karƒ±lmamƒ±≈üsa
                found_value = "Bulunamadƒ±"
                
                # Pattern listesinde her pattern'i dene
                for pattern in pattern_list:
                    matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)
                    if matches:
                        if isinstance(matches[0], tuple):
                            # Tuple i√ßindeki bo≈ü olmayan ilk deƒüeri al
                            value = [m for m in matches[0] if m.strip()]
                            if value:
                                found_value = value[0].strip()
                                break
                        else:
                            found_value = matches[0].strip()
                            break
                
                values[key] = found_value
        
        # √ñl√ß√ºm verilerini analiz et
        self.analyze_measurement_data(text, values)
        
        return values
    
    def analyze_measurement_data(self, text: str, values: Dict[str, Any]):
        """√ñl√ß√ºm verilerini analiz et"""
        # RLO deƒüerlerini topla - daha geni≈ü pattern
        rlo_patterns = [
            r"(\d+[.,]?\d*)\s*(?:mŒ©|mohm|ohm|Œ©)",
            r"(\d+)\s*(?:4x[2-9](?:[.,]\d+)?|4x4)\s*(?:[2-9](?:[.,]\d+)?|4)\s*500",
            r"(\d+)\s*(?:mŒ©|mohm|ohm|Œ©)"
        ]
        
        rlo_values = []
        for pattern in rlo_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            for match in matches:
                try:
                    # Virg√ºl√º noktaya √ßevir ve sayƒ±ya √ßevir
                    value_str = str(match).replace(',', '.')
                    rlo_values.append(float(value_str))
                except:
                    continue
        
        if rlo_values:
            values["rlo_min"] = f"{min(rlo_values):.1f} mŒ©"
            values["rlo_max"] = f"{max(rlo_values):.1f} mŒ©"
            values["rlo_ortalama"] = f"{sum(rlo_values)/len(rlo_values):.1f} mŒ©"
        else:
            values["rlo_min"] = "Bulunamadƒ±"
            values["rlo_max"] = "Bulunamadƒ±"
            values["rlo_ortalama"] = "Bulunamadƒ±"
        
        # Kesit bilgilerini analiz et - daha geni≈ü pattern
        kesit_patterns = [
            r"4x4",
            r"4x2[.,]5", 
            r"4x6",
            r"4x10",
            r"Y√ºk\s*ƒ∞letken",
            r"Load\s*Conductor",
            r"PE\s*ƒ∞letken",
            r"PE\s*Conductor"
        ]
        
        total_kesit_count = 0
        for pattern in kesit_patterns:
            count = len(re.findall(pattern, text, re.IGNORECASE))
            total_kesit_count += count
        
        values["toplam_olcum_nokta"] = total_kesit_count
        
        # Uygunluk durumlarƒ±nƒ± say
        uygun_pattern = r"UYGUNUYGUN"
        uygun_matches = re.findall(uygun_pattern, text)
        values["uygun_nokta_sayisi"] = len(uygun_matches)
        
        # Uygunsuz √∂l√ß√ºmleri tespit et
        self.find_non_compliant_measurements(text, values)
        
        # Genel sonu√ß
        if len(uygun_matches) == values["toplam_olcum_nokta"] and values["toplam_olcum_nokta"] > 0:
            values["genel_sonuc"] = "T√úM NOKTALAR UYGUN"
        else:
            values["genel_sonuc"] = f"{values['toplam_olcum_nokta'] - len(uygun_matches)} NOKTA UYGUNSUZ"
        
        # Hat/b√∂lge bilgileri
        hat_pattern = r"(8X45|8X50|8X9J|9J73|8X52|8X60|8X62|8X70)\s*(?:R[1-9])?\s*Hatt[ƒ±i]"
        hat_matches = re.findall(hat_pattern, text, re.IGNORECASE)
        if hat_matches:
            unique_hats = list(set(hat_matches))
            values["makine_hatlari"] = ", ".join(unique_hats)
        else:
            values["makine_hatlari"] = "Bulunamadƒ±"
    
    def find_non_compliant_measurements(self, text: str, values: Dict[str, Any]):
        """Uygunsuz √∂l√ß√ºmleri tespit et"""
        # 500 mŒ©'dan b√ºy√ºk deƒüerleri ve D.Y. deƒüerlerini bul
        lines = text.split('\n')
        non_compliant = []
        
        for i, line in enumerate(lines):
            # Sƒ±ra numarasƒ± kontrol√º
            sira_match = re.search(r'(\d+)\s', line)
            if sira_match:
                sira = sira_match.group(1)
                
                # Y√ºksek RLO deƒüeri kontrol√º (>500 mŒ©) - daha geni≈ü pattern
                high_rlo_patterns = [
                    r'(\d{3,4})\s*(?:4x[2-9](?:[.,]\d+)?|4x4)\s*(?:[2-9](?:[.,]\d+)?|4)\s*500(\d+)\s*mŒ©\s*<\s*500\s*mŒ©',
                    r'(\d{3,4})\s*(?:mŒ©|mohm|ohm|Œ©)',
                    r'(\d{3,4})[.,]?\d*\s*(?:mŒ©|mohm|ohm|Œ©)'
                ]
                
                for pattern in high_rlo_patterns:
                    high_rlo_match = re.search(pattern, line, re.IGNORECASE)
                    if high_rlo_match:
                        try:
                            rlo_value = float(str(high_rlo_match.group(1)).replace(',', '.'))
                            if rlo_value > 500:
                                # Hat ve ekipman bilgisi - daha geni≈ü pattern
                                hat_patterns = [
                                    r'(8X\d+R?\d*)\s*(?:Hatt[ƒ±i]|Line|Zone)?\s*(.*?)(?:\s+\d+)',
                                    r'(8X\d+R?\d*)\s*(.*?)(?:\s+\d+)',
                                    r'(Line\s*\d+|Zone\s*\d+)\s*(.*?)(?:\s+\d+)'
                                ]
                                
                                for hat_pattern in hat_patterns:
                                    hat_match = re.search(hat_pattern, line, re.IGNORECASE)
                                    if hat_match:
                                        hat = hat_match.group(1)
                                        ekipman = hat_match.group(2).strip()
                                        non_compliant.append({
                                            'sira': sira,
                                            'rlo': f"{rlo_value:.1f} mŒ©",
                                            'hat': hat,
                                            'ekipman': ekipman,
                                            'durum': 'Y√ºksek Diren√ß'
                                        })
                                        break
                                break
                        except:
                            continue
                
                # D.Y. (Deƒüer Yok) kontrol√º - daha geni≈ü pattern
                if '*D.Y' in line or 'D.Y' in line or 'N/A' in line or 'N/A' in line:
                    hat_patterns = [
                        r'(8X\d+R?\d*)\s*(?:Hatt[ƒ±i]|Line|Zone)?\s*(.*?)(?:\s+|$)',
                        r'(8X\d+R?\d*)\s*(.*?)(?:\s+|$)',
                        r'(Line\s*\d+|Zone\s*\d+)\s*(.*?)(?:\s+|$)'
                    ]
                    
                    for hat_pattern in hat_patterns:
                        hat_match = re.search(hat_pattern, line, re.IGNORECASE)
                        if hat_match:
                            hat = hat_match.group(1)
                            ekipman = hat_match.group(2).strip()
                            non_compliant.append({
                                'sira': sira,
                                'rlo': 'D.Y.',
                                'hat': hat,
                                'ekipman': ekipman,
                                'durum': '√ñl√ß√ºm Yapƒ±lamadƒ±'
                            })
                            break
        
        values["uygunsuz_olcumler"] = non_compliant
    
    def calculate_scores(self, analysis_results: Dict[str, Dict[str, GroundingAnalysisResult]]) -> Dict[str, Any]:
        """Puanlarƒ± hesaplama"""
        category_scores = {}
        total_score = 0
        total_max_score = 100
        
        for category, results in analysis_results.items():
            category_max = self.criteria_weights[category]
            category_earned = sum(result.score for result in results.values())
            category_possible = sum(result.max_score for result in results.values())
            
            # Kategori puanƒ±nƒ± aƒüƒ±rlƒ±ƒüa g√∂re normalize et
            normalized_score = (category_earned / category_possible * category_max) if category_possible > 0 else 0
            
            category_scores[category] = {
                "earned": category_earned,
                "possible": category_possible,
                "normalized": round(normalized_score, 2),
                "max_weight": category_max,
                "percentage": round((category_earned / category_possible * 100), 2) if category_possible > 0 else 0
            }
            
            total_score += normalized_score
        
        return {
            "category_scores": category_scores,
            "total_score": round(total_score, 2),
            "total_max_score": total_max_score,
            "overall_percentage": round((total_score / total_max_score * 100), 2)
        }
    
    def generate_detailed_report(self, file_path: str) -> Dict[str, Any]:
        """Detaylƒ± rapor olu≈üturma"""
        logger.info("Topraklama S√ºreklilik rapor analizi ba≈ülatƒ±lƒ±yor...")
        
        # Dosyadan metin √ßƒ±kar ve dil bilgisi al
        text, detected_language = self.get_file_text(file_path)
        if not text:
            return {"error": "Dosya okunamadƒ±"}
        
        # Dil bilgisini logla
        language_name = self.get_language_name(detected_language)
        logger.info(f"üìñ Belge dili: {language_name}")
        if detected_language != 'tr':
            logger.info("üîÑ √áeviri i≈ülemi tamamlandƒ±")
        
        # Tarih ge√ßerliliƒüi kontrol√º (1 yƒ±l kuralƒ±)
        date_valid, olcum_tarihi, rapor_tarihi, date_message = self.check_date_validity(text, file_path)
        
        # Spesifik deƒüerleri √ßƒ±kar
        extracted_values = self.extract_specific_values(text, file_path)
        
        # Dil bilgisini extracted_values'a ekle
        extracted_values['detected_language'] = detected_language
        extracted_values['language_name'] = language_name
        
        # Her kategori i√ßin analiz yap
        analysis_results = {}
        for category in self.criteria_weights.keys():
            analysis_results[category] = self.analyze_criteria(text, category)
        
        # Puanlarƒ± hesapla
        scores = self.calculate_scores(analysis_results)
        
        # Final karar: Tarih ge√ßersizse puan ne olursa olsun FAILED
        final_status = "PASSED"
        if not date_valid:
            final_status = "FAILED"
            fail_reason = "√ñl√ß√ºm tarihi ile rapor tarihi arasƒ±ndaki fark 1 yƒ±ldan fazla"
        elif scores["overall_percentage"] < 70:
            final_status = "FAILED"
            fail_reason = f"Toplam puan yetersiz (%{scores['overall_percentage']:.1f} < 70)"
        else:
            fail_reason = None
        
        # √ñneriler olu≈ütur
        recommendations = self.generate_recommendations(analysis_results, scores, date_valid)
        
        report = {
            "analiz_tarihi": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "dosya_bilgileri": {
                "file_path": file_path,
                "file_type": os.path.splitext(file_path)[1]
            },
            "tarih_gecerliligi": {
                "gecerli": date_valid,
                "olcum_tarihi": olcum_tarihi,
                "rapor_tarihi": rapor_tarihi,
                "mesaj": date_message
            },
            "cikarilan_degerler": extracted_values,
            "kategori_analizleri": analysis_results,
            "puanlama": scores,
            "oneriler": recommendations,
            "ozet": {
                "toplam_puan": scores["total_score"],
                "yuzde": scores["overall_percentage"],
                "final_durum": final_status,
                "tarih_durumu": "GE√áERLƒ∞" if date_valid else "GE√áERSƒ∞Z",
                "gecme_durumu": "PASSED" if final_status == "PASSED" else "FAILED",
                "fail_nedeni": fail_reason
            }
        }
        
        return report
    
    def generate_recommendations(self, analysis_results: Dict, scores: Dict, date_valid: bool) -> List[str]:
        """√ñneriler olu≈üturma"""
        recommendations = []
        
        # Tarih kontrol√º √∂ncelikli
        if not date_valid:
            recommendations.append("üö® KRƒ∞Tƒ∞K: √ñl√ß√ºm tarihi ile rapor tarihi arasƒ±ndaki fark 1 yƒ±ldan fazla - RAPOR GE√áERSƒ∞Z")
            recommendations.append("- Yeni √∂l√ß√ºm yapƒ±lmasƒ± gereklidir")
            recommendations.append("- √ñl√ß√ºm tarihi rapor tarihinden en fazla 1 yƒ±l √∂nce olmalƒ±dƒ±r")
        
        # Kategori bazlƒ± √∂neriler
        for category, results in analysis_results.items():
            category_score = scores["category_scores"][category]["percentage"]
            
            if category_score < 50:
                recommendations.append(f"‚ùå {category} b√∂l√ºm√º yetersiz (%{category_score:.1f})")
                
                # Eksik kriterler
                missing_criteria = [name for name, result in results.items() if not result.found]
                if missing_criteria:
                    recommendations.append(f"  Eksik kriterler: {', '.join(missing_criteria)}")
                
                # Kategori √∂zel √∂neriler
                if category == "Genel Rapor Bilgileri":
                    recommendations.append("  - Proje adƒ± ve numarasƒ± eksiksiz belirtilmelidir")
                    recommendations.append("  - √ñl√ß√ºm ve rapor tarihleri a√ßƒ±k√ßa belirtilmelidir")
                    recommendations.append("  - Rapor numarasƒ± ve revizyon bilgisi eklenmeli")
                
                elif category == "√ñl√ß√ºm Metodu ve Standart Referanslarƒ±":
                    recommendations.append("  - √ñl√ß√ºm cihazƒ± marka/model bilgileri eklenmeli")
                    recommendations.append("  - Kalibrasyon sertifikasƒ± bilgileri verilmeli")
                    recommendations.append("  - EN 60204-1 Tablo 10 referansƒ± yapƒ±lmalƒ±")
                
                elif category == "√ñl√ß√ºm Sonu√ß Tablosu":
                    recommendations.append("  - T√ºm √∂l√ß√ºm noktalarƒ± i√ßin RLO deƒüerleri belirtilmeli")
                    recommendations.append("  - Y√ºk ve PE iletken kesitleri girilmeli")
                    recommendations.append("  - EN 60204 Tablo 10 referans deƒüerleri eklenmeli")
                    recommendations.append("  - Uygunluk durumu her nokta i√ßin belirtilmeli")
                
                elif category == "Uygunluk Deƒüerlendirmesi":
                    recommendations.append("‚ö†Ô∏è Uygunsuz noktalar i√ßin teknik a√ßƒ±klama ekleyin")
                    recommendations.append("üìä Toplam √∂l√ß√ºm sayƒ±sƒ± ve uygunluk oranƒ±nƒ± belirtin")
                    recommendations.append("üîç 500 mŒ© limit deƒüeri a≈üƒ±mlarƒ±nƒ± i≈üaretleyin")
                
                elif category == "G√∂rsel ve Teknik D√∂k√ºmantasyon":
                    recommendations.append("  - √ñl√ß√ºm yapƒ±lan alan fotoƒüraflarƒ± eklenmeli")
                    recommendations.append("  - √ñl√ß√ºm cihazƒ± ve baƒülantƒ± fotoƒüraflarƒ± √ßekilmeli")
                    recommendations.append("  - √ñl√ß√ºm noktalarƒ±nƒ±n kroki/≈üemasƒ± hazƒ±rlanmalƒ±")
                
                elif category == "Sonu√ß ve √ñneriler":
                    recommendations.append("  - Genel uygunluk sonucu a√ßƒ±k√ßa belirtilmeli")
                    recommendations.append("  - Standartlara atƒ±f yapƒ±lmalƒ±")
                    recommendations.append("  - ƒ∞yile≈ütirme √∂nerileri detaylandƒ±rƒ±lmalƒ±")
                    recommendations.append("  - Tekrar √∂l√ß√ºm periyodu √∂nerilmeli")
            
            elif category_score < 80:
                recommendations.append(f"‚ö†Ô∏è {category} b√∂l√ºm√º geli≈ütirilmeli (%{category_score:.1f})")
            
            else:
                recommendations.append(f"‚úÖ {category} b√∂l√ºm√º yeterli (%{category_score:.1f})")
        
        # Genel √∂neriler
        if scores["overall_percentage"] < 70:
            recommendations.append("\nüö® GENEL √ñNERƒ∞LER:")
            recommendations.append("- Rapor EN 60204-1 standardƒ±na tam uyumlu hale getirilmelidir")
            recommendations.append("- IEC 60364 standart referanslarƒ± eklenmeli")
            recommendations.append("- Eksik bilgiler tamamlanmalƒ±dƒ±r")
            recommendations.append("- √ñl√ß√ºm sonu√ßlarƒ± tablo formatƒ±nda d√ºzenlenmeli")
        
        # Ba≈üarƒ±lƒ± durumda
        if scores["overall_percentage"] >= 70 and date_valid:
            recommendations.append("\n‚úÖ RAPOR BA≈ûARILI")
            recommendations.append("- T√ºm gerekli kriterler saƒülanmƒ±≈ütƒ±r")
            recommendations.append("- Rapor standarltara uygun olarak hazƒ±rlanmƒ±≈ütƒ±r")
        
        return recommendations
    
    def save_report_to_excel(self, report: Dict, output_path: str):
        """Raporu Excel'e kaydetme"""
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            # √ñzet sayfa
            ozet_data = {
                'Kriter': ['Toplam Puan', 'Y√ºzde', 'Final Durum', 'Tarih Durumu', 'Ge√ßme Durumu'],
                'Deƒüer': [
                    report['ozet']['toplam_puan'],
                    f"%{report['ozet']['yuzde']}",
                    report['ozet']['final_durum'],
                    report['ozet']['tarih_durumu'],
                    report['ozet']['gecme_durumu']
                ]
            }
            if report['ozet']['fail_nedeni']:
                ozet_data['Kriter'].append('Ba≈üarƒ±sƒ±zlƒ±k Nedeni')
                ozet_data['Deƒüer'].append(report['ozet']['fail_nedeni'])
            
            pd.DataFrame(ozet_data).to_excel(writer, sheet_name='√ñzet', index=False)
            
            # √áƒ±karƒ±lan deƒüerler
            values_data = []
            for key, value in report['cikarilan_degerler'].items():
                values_data.append({'Kriter': key, 'Deƒüer': value})
            pd.DataFrame(values_data).to_excel(writer, sheet_name='√áƒ±karƒ±lan Deƒüerler', index=False)
            
            # Kategori detaylarƒ±
            for category, results in report['kategori_analizleri'].items():
                category_data = []
                for criterion, result in results.items():
                    category_data.append({
                        'Kriter': criterion,
                        'Bulundu': result.found,
                        'ƒ∞√ßerik': result.content,
                        'Puan': result.score,
                        'Max Puan': result.max_score
                    })
                
                sheet_name = category[:31]  # Excel sheet name limit
                pd.DataFrame(category_data).to_excel(writer, sheet_name=sheet_name, index=False)
        
        logger.info(f"Rapor Excel dosyasƒ± kaydedildi: {output_path}")
    
    def save_report_to_json(self, report: Dict, output_path: str):
        """Raporu JSON'a kaydetme"""
        # GroundingAnalysisResult objelerini dict'e √ßevir
        json_report = {}
        for key, value in report.items():
            if key == 'kategori_analizleri':
                json_report[key] = {}
                for category, results in value.items():
                    json_report[key][category] = {}
                    for criterion, result in results.items():
                        json_report[key][category][criterion] = asdict(result)
            else:
                json_report[key] = value
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(json_report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"Rapor JSON dosyasƒ± kaydedildi: {output_path}")

def main():
    """Ana fonksiyon"""
    analyzer = GroundingContinuityReportAnalyzer()
    
    # Dosya yolu - Proje root'undaki belgeyi analiz et
    file_path = "E21.207 - Toyota - Chifong LVD √ñl√ß√ºm .pdf"
    
    # Dosyanƒ±n varlƒ±ƒüƒ±nƒ± kontrol et
    if not os.path.exists(file_path):
        print(f"‚ùå Dosya bulunamadƒ±: {file_path}")
        print("Mevcut dosyalar:")
        for file in os.listdir("."):
            if file.endswith(('.pdf', '.docx', '.xlsx')):
                print(f"  - {file}")
        return
    
    print("‚ö° Topraklama S√ºreklilik Rapor Analizi Ba≈ülatƒ±lƒ±yor...")
    print("=" * 60)
    
    # Analizi √ßalƒ±≈ütƒ±r
    report = analyzer.generate_detailed_report(file_path)
    
    if "error" in report:
        print(f"‚ùå Hata: {report['error']}")
        return
    
    print("\nüìä ANALƒ∞Z SONU√áLARI")
    print("=" * 60)
    
    print(f"üìÖ Analiz Tarihi: {report['analiz_tarihi']}")
    print(f"üîç Tespit Edilen Dil: {report['cikarilan_degerler'].get('language_name', 'Bilinmiyor')}")
    print(f"üìã Toplam Puan: {report['ozet']['toplam_puan']}/100")
    print(f"üìà Y√ºzde: %{report['ozet']['yuzde']:.1f}")
    print(f"üéØ Durum: {report['ozet']['final_durum']}")
    print(f"üìÑ Rapor Tipi: LVD √ñl√ß√ºm Raporu")
    
    print(f"\nüìÖ TARƒ∞H GE√áERLƒ∞Lƒ∞ƒûƒ∞")
    print("-" * 40)
    print(f"√ñl√ß√ºm Tarihi: {report['tarih_gecerliligi']['olcum_tarihi']}")
    print(f"Rapor Tarihi: {report['tarih_gecerliligi']['rapor_tarihi']}")
    print(f"Ge√ßerlilik: {report['tarih_gecerliligi']['mesaj']}")
    
    print("\nüìã √ñNEMLƒ∞ √áIKARILAN DEƒûERLER")
    print("-" * 40)
    important_values = {
        "proje_no": "Proje No",
        "rapor_numarasi": "Rapor Numarasƒ±", 
        "musteri": "M√º≈üteri",
        "proje_adi": "Proje Adƒ±",
        "tesis_adi": "Tesis/Hat",
        "olcum_cihazi": "√ñl√ß√ºm Cihazƒ±",
        "firma_personel": "Hazƒ±rlayan Firma",
        "toplam_olcum_nokta": "Toplam √ñl√ß√ºm Noktasƒ±",
        "uygun_nokta_sayisi": "Uygun Nokta Sayƒ±sƒ±",
        "genel_sonuc": "Genel Sonu√ß"
    }
    
    for key, display_name in important_values.items():
        if key in report['cikarilan_degerler']:
            print(f"{display_name}: {report['cikarilan_degerler'][key]}")
    
    print("\nüìä KATEGORƒ∞ PUANLARI VE DETAYLAR")
    print("=" * 60)
    
    # Her kategori i√ßin detaylƒ± analiz
    categories = [
        ("Genel Rapor Bilgileri", "1"),
        ("√ñl√ß√ºm Metodu ve Standart Referanslarƒ±", "2"), 
        ("√ñl√ß√ºm Sonu√ß Tablosu", "3"),
        ("Uygunluk Deƒüerlendirmesi", "4"),
        ("G√∂rsel ve Teknik D√∂k√ºmantasyon", "5"),
        ("Sonu√ß ve √ñneriler", "6")
    ]
    
    for category, num in categories:
        if category in report['puanlama']['category_scores']:
            score_data = report['puanlama']['category_scores'][category]
            percentage = score_data['percentage']
            print(f"\nüîç {category}: {score_data['normalized']:.1f}/{score_data['max_weight']} (%{percentage:.1f})")
            print("-" * 50)
            
            # Bu kategorinin analiz sonu√ßlarƒ±nƒ± g√∂ster
            if category in report['kategori_analizleri']:
                category_analysis = report['kategori_analizleri'][category]
                for criterion_name, criterion_result in category_analysis.items():
                    criterion_display = criterion_name.replace('_', ' ').title()
                    if hasattr(criterion_result, 'found') and criterion_result.found:
                        print(f"  ‚úÖ {criterion_display}: {criterion_result.score}/{criterion_result.max_score} puan")
                    else:
                        print(f"  ‚ùå {criterion_display}: 0/{criterion_result.max_score} puan - BULUNAMADI")
    
    print("\n" + "=" * 60)
    
    print("\nüí° √ñNERƒ∞LER VE DEƒûERLENDƒ∞RME")
    print("-" * 40)
    for recommendation in report['oneriler']:
        print(recommendation)
    
    print("\nüìã GENEL DEƒûERLENDƒ∞RME")
    print("=" * 60)
    
    if report['ozet']['final_durum'] == "PASSED":
        print("‚úÖ SONU√á: GE√áERLƒ∞")
        print(f"üåü Toplam Ba≈üarƒ±: %{report['ozet']['yuzde']:.1f}")
        print("üìù Deƒüerlendirme: Topraklama S√ºreklilik raporu genel olarak yeterli kriterleri saƒülamaktadƒ±r.")
    else:
        print("‚ùå SONU√á: GE√áERSƒ∞Z")
        print(f"‚ö†Ô∏è Toplam Ba≈üarƒ±: %{report['ozet']['yuzde']:.1f}")
        print("üìù Deƒüerlendirme: Topraklama S√ºreklilik raporu minimum gereklilikleri saƒülamamaktadƒ±r.")
        
        # Ba≈üarƒ±sƒ±zlƒ±k nedeni varsa yazdƒ±r
        if report['ozet']['fail_nedeni']:
            print(f"üö® Ba≈üarƒ±sƒ±zlƒ±k Nedeni: {report['ozet']['fail_nedeni']}")
        
        print("\n‚ö†Ô∏è EKSƒ∞K GEREKLƒ∞Lƒ∞KLER:")
        for category, results in report['kategori_analizleri'].items():
            missing_items = []
            for criterion, result in results.items():
                if not result.found:
                    missing_items.append(criterion)
            
            if missing_items:
                print(f"\nüîç {category}:")
                for item in missing_items[:3]:  # ƒ∞lk 3 eksik item'ƒ± g√∂ster
                    readable_name = item.replace('_', ' ').title()
                    print(f"   ‚ùå {readable_name}")
        
        print("\nüìå YAPILMASI GEREKENLER:")
        print("1. Eksik belgelendirmeleri tamamlayƒ±n")
        print("2. √ñl√ß√ºm cihazƒ± ve kalibrasyon bilgilerini ekleyin")
        print("3. √ñl√ß√ºm sonu√ß tablolarƒ±nƒ± detaylandƒ±rƒ±n")
        print("4. Uygunluk deƒüerlendirmelerini g√º√ßlendirin")
        print("5. G√∂rsel dok√ºmantasyonu artƒ±rƒ±n")
        print("6. Standart referanslarƒ±nƒ± ekleyin")
        
        # Uygunsuz √∂l√ß√ºmler varsa ekstra bilgi
        uygunsuz_olcumler = report['cikarilan_degerler'].get('uygunsuz_olcumler', [])
        if uygunsuz_olcumler:
            print("\nüö® UYGUNSUZ √ñL√á√úMLER:")
            for measurement in uygunsuz_olcumler[:5]:  # ƒ∞lk 5 uygunsuz √∂l√ß√ºm√º g√∂ster
                if measurement['durum'] == 'Y√ºksek Diren√ß':
                    print(f"   ‚ö†Ô∏è Sƒ±ra {measurement['sira']}: {measurement['rlo']} > 500 mŒ©")
                else:
                    print(f"   ‚ö†Ô∏è Sƒ±ra {measurement['sira']}: √ñl√ß√ºm yapƒ±lamadƒ± (*D.Y.)")
            
            if len(uygunsuz_olcumler) > 5:
                print(f"   ... ve {len(uygunsuz_olcumler) - 5} uygunsuz √∂l√ß√ºm daha")

if __name__ == "__main__":
    main()
