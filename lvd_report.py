import re
import os
import json
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Any
import PyPDF2
from docx import Document
import pandas as pd
from dataclasses import dataclass, asdict
import logging

# Offline Ã§eviri iÃ§in Helsinki-NLP modelleri
try:
    from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM
    OFFLINE_TRANSLATION_AVAILABLE = True
except ImportError:
    OFFLINE_TRANSLATION_AVAILABLE = False
    print("âš ï¸ Offline Ã§eviri desteÄŸi iÃ§in: pip install transformers torch sentencepiece")

# Dil tespiti iÃ§in
try:
    from langdetect import detect
    LANGUAGE_DETECTION_AVAILABLE = True
except ImportError:
    LANGUAGE_DETECTION_AVAILABLE = False
    print("âš ï¸ Dil tespiti iÃ§in: pip install langdetect")

# Logging konfigÃ¼rasyonu
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class GroundingContinuityCriteria:
    """Topraklama SÃ¼reklilik rapor kriterleri veri sÄ±nÄ±fÄ±"""
    genel_rapor_bilgileri: Dict[str, Any]
    olcum_metodu_standart_referanslari: Dict[str, Any]
    olcum_sonuc_tablosu: Dict[str, Any]
    uygunluk_degerlendirmesi: Dict[str, Any]
    gorsel_teknik_dokumantasyon: Dict[str, Any]
    sonuc_oneriler: Dict[str, Any]

@dataclass
class GroundingAnalysisResult:
    """Topraklama SÃ¼reklilik analiz son    if status == "FAIL":
        print("### ğŸš« GEÃ‡EMEMENÄ°N NEDENLERÄ°:")
        print(f"1. **GeÃ§me sÄ±nÄ±rÄ±:** 70 puan, **AlÄ±nan:** {total_score} puan")
        
        # Tarih kontrolÃ¼
        if not report['tarih_gecerliligi']['gecerli']:
            print("2. **KRÄ°TÄ°K:** Ã–lÃ§Ã¼m tarihi ile rapor tarihi arasÄ±ndaki fark 1 yÄ±ldan fazla")
        
        print("3. Kritik eksiklikler:")
        
        for category in categories:
            cat_name = category[0]
            if cat_name in report['puanlama']['category_scores']:
                score_data = report['puanlama']['category_scores'][cat_name]
                if score_data['percentage'] < 50:
                    print(f"   - {cat_name} yetersiz")
        
        uygunsuz_count = len(report['cikarilan_degerler'].get('uygunsuz_olcumler', []))
        if uygunsuz_count > 0:
            print(f"   - {uygunsuz_count} nokta uygunsuzluk var ve Ã§Ã¶zÃ¼m Ã¶nerisi yok")"""
    criteria_name: str
    found: bool
    content: str
    score: int
    max_score: int
    details: Dict[str, Any]

class GroundingContinuityReportAnalyzer:
    """Topraklama SÃ¼reklilik rapor analiz sÄ±nÄ±fÄ±"""
    
    def __init__(self):
        # Offline Ã§eviri modellerini baÅŸlat
        self.translation_models = {}
        self.language_detector = None
        
        if OFFLINE_TRANSLATION_AVAILABLE and LANGUAGE_DETECTION_AVAILABLE:
            self.init_translation_models()
        
        self.criteria_weights = {
            "Genel Rapor Bilgileri": 15,
            "Ã–lÃ§Ã¼m Metodu ve Standart ReferanslarÄ±": 15,
            "Ã–lÃ§Ã¼m SonuÃ§ Tablosu": 25,
            "Uygunluk DeÄŸerlendirmesi": 20,
            "GÃ¶rsel ve Teknik DÃ¶kÃ¼mantasyon": 10,
            "SonuÃ§ ve Ã–neriler": 15
        }
        
        self.criteria_details = {
            "Genel Rapor Bilgileri": {
                "proje_adi_numarasi": {"pattern": r"(?:Project\s*(?:Name|No)|Proje\s*(?:Ad[Ä±i]|No)|Report\s*Title|Document\s*Title|E\d{2}\.\d{3}|C\d{2}\.\d{3}|T\d{2,3}[-.]?\d{3,4})", "weight": 3},
                "olcum_tarihi": {"pattern": r"(?:Measurement\s*Date|Ã–lÃ§Ã¼m\s*Tarihi|Test\s*Date|Date\s*of\s*(?:Test|Measurement)|Measured\s*on|Tested\s*on|\d{1,2}[./\-]\d{1,2}[./\-]\d{4})", "weight": 3},
                "rapor_tarihi": {"pattern": r"(?:Report\s*Date|Rapor\s*Tarihi|Issue\s*Date|Document\s*Date|Prepared\s*on|Created\s*on|Date|Tarih|\d{1,2}[./\-]\d{1,2}[./\-]\d{4})", "weight": 3},
                "tesis_bolge_hat": {"pattern": r"(?:Customer|MÃ¼ÅŸteri|Client|Facility|Tesis|Plant|Factory|Company|Firma|Toyota|DANONE|Ford|BOSCH)", "weight": 2},
                "rapor_numarasi": {"pattern": r"(?:Report\s*No|Rapor\s*No|Document\s*No|Belge\s*No|E\d{2}\.\d{3}|C\d{2}\.\d{3}|SM\s*\d+|MCC\d+)", "weight": 2},
                "revizyon": {"pattern": r"(?:Version|Revizyon|Rev\.?|v)\s*[:=]?\s*(\d+|[A-Z])", "weight": 1},
                "firma_personel": {"pattern": r"(?:Prepared\s*by|HazÄ±rlayan|Performed\s*by|Ã–lÃ§Ã¼mÃ¼\s*Yapan|Consultant|Engineer|PILZ)", "weight": 1}
            },
            "Ã–lÃ§Ã¼m Metodu ve Standart ReferanslarÄ±": {
                "olcum_cihazi": {"pattern": r"(?:Measuring\s*Instrument|Ã–lÃ§Ã¼m\s*Cihaz[Ä±i]|Test\s*Equipment|Multimeter|Multimetre|Ohmmeter|Instrument|Equipment|Device|Tester|Fluke|Metrix|Chauvin|Megger|Hioki)", "weight": 6},
                "kalibrasyon": {"pattern": r"(?:Calibration|Kalibrasyon|Kalibre|Certificate|Sertifika|Cal\s*Date)", "weight": 4},
                "standartlar": {"pattern": r"(?:EN\s*60204[-\s]*1?|IEC\s*60364|Standard|Standart)", "weight": 5}
            },
            "Ã–lÃ§Ã¼m SonuÃ§ Tablosu": {
                "sira_numarasi": {"pattern": r"(?:S[Ä±i]ra\s*(?:No|Numaras[Ä±i])|^\s*\d+\s)", "weight": 3},
                "makine_hat_bolge": {"pattern": r"(?:8X45|8X50|8X9J|9J73|8X52|8X60|8X62|8X70)\s*(?:R[1-9])?\s*(?:Hatt[Ä±i]|Line|Zone|BÃ¶lge)", "weight": 3},
                "olcum_noktasi": {"pattern": r"(?:Robot\s*\d+\.\s*Eksen\s*Motoru|KalemtraÅŸ|Lift\s*and\s*Shift|Motor|Ekipman|Equipment|Device)", "weight": 3},
                "rlo_degeri": {"pattern": r"(\d+[.,]?\d*)\s*(?:mÎ©|mohm|ohm|Î©)", "weight": 5},
                "yuk_iletken_kesiti": {"pattern": r"(?:4x4|4x2[.,]5|4x6|4x10|YÃ¼k\s*Ä°letken|Load\s*Conductor|PE\s*Ä°letken|PE\s*Conductor)", "weight": 4},
                "referans_degeri": {"pattern": r"(?:500\s*mÎ©|500\s*ohm|500\s*Î©|EN\s*60204|IEC\s*60364)", "weight": 3},
                "uygunluk_durumu": {"pattern": r"(?:UYGUN|OK|PASS|Compliant|Uygun)", "weight": 4},
                "kesit_uygunlugu": {"pattern": r"(?:UYGUN|OK|PASS|Compliant|Uygun)", "weight": 3}
            },
            "Uygunluk DeÄŸerlendirmesi": {
                "toplam_olcum_nokta": {"pattern": r"(?:222|220|200|Toplam.*\d+)", "weight": 5},
                "uygun_nokta_sayisi": {"pattern": r"(?:211|210|UYGUN)", "weight": 5},
                "uygunsuz_isaretleme": {"pattern": r"\*D\.Y", "weight": 5, "reverse_logic": True},  # Uygunsuzluk bulunmazsa tam puan
                "standart_referans_uygunluk": {"pattern": r"(?:500\s*mÎ©|EN\s*60204)", "weight": 5}
            },
            "GÃ¶rsel ve Teknik DÃ¶kÃ¼mantasyon": {
                "cihaz_baglanti_fotografi": {"pattern": r"(?:Cihaz.*FotoÄŸraf|BaÄŸlant[Ä±i].*FotoÄŸraf|Ã–lÃ§Ã¼m.*Cihaz|Photo|Image|Figure|Resim|GÃ¶rsel)", "weight": 10}
            },
            "SonuÃ§ ve Ã–neriler": {
                "genel_uygunluk": {"pattern": r"(?:Genel\s*Uygunluk|SonuÃ§|UYGUN|UYGUNSUZ|Result|Conclusion|Compliant|Non-compliant)", "weight": 8},
                "standart_atif": {"pattern": r"(?:EN\s*60204|IEC\s*60364|Standart.*AtÄ±f|Standart.*Referans|Standard.*Reference)", "weight": 7}
            }
        }
    
    def init_translation_models(self):
        """Offline Ã§eviri modellerini baÅŸlat"""
        try:
            logger.info("Offline Ã§eviri modelleri yÃ¼kleniyor...")
            
            # En yaygÄ±n diller iÃ§in Helsinki-NLP modelleri
            model_mapping = {
                'en': 'Helsinki-NLP/opus-mt-en-tr',  # Ä°ngilizce -> TÃ¼rkÃ§e
                'de': 'Helsinki-NLP/opus-mt-de-tr',  # Almanca -> TÃ¼rkÃ§e
                'fr': 'Helsinki-NLP/opus-mt-fr-tr',  # FransÄ±zca -> TÃ¼rkÃ§e
                'es': 'Helsinki-NLP/opus-mt-es-tr',  # Ä°spanyolca -> TÃ¼rkÃ§e
                'it': 'Helsinki-NLP/opus-mt-it-tr',  # Ä°talyanca -> TÃ¼rkÃ§e
            }
            
            for lang_code, model_name in model_mapping.items():
                try:
                    # Model varsa yÃ¼kle, yoksa atla
                    tokenizer = AutoTokenizer.from_pretrained(model_name)
                    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
                    
                    self.translation_models[lang_code] = {
                        'tokenizer': tokenizer,
                        'model': model,
                        'pipeline': pipeline('translation', 
                                           model=model, 
                                           tokenizer=tokenizer,
                                           device=-1)  # CPU kullan
                    }
                    logger.info(f"âœ… {lang_code.upper()} -> TR modeli yÃ¼klendi")
                except Exception as e:
                    logger.warning(f"âš ï¸ {lang_code.upper()} -> TR modeli yÃ¼klenemedi: {e}")
                    
            logger.info(f"Toplam {len(self.translation_models)} Ã§eviri modeli hazÄ±r")
            
        except Exception as e:
            logger.error(f"Ã‡eviri modelleri baÅŸlatÄ±lamadÄ±: {e}")
    
    def detect_language(self, text: str) -> str:
        """Metin dilini tespit et"""
        if not LANGUAGE_DETECTION_AVAILABLE:
            return 'tr'
        
        try:
            # Sadece ilk 500 karakterle dil tespiti (hÄ±z iÃ§in)
            sample_text = text[:500].strip()
            if not sample_text:
                return 'tr'
                
            detected_lang = detect(sample_text)
            logger.info(f"Tespit edilen dil: {detected_lang}")
            return detected_lang
            
        except Exception as e:
            logger.warning(f"Dil tespiti baÅŸarÄ±sÄ±z: {e}")
            return 'tr'
    
    def translate_to_turkish(self, text: str, source_lang: str) -> str:
        """Metni TÃ¼rkÃ§e'ye Ã§evir"""
        if source_lang == 'tr' or source_lang not in self.translation_models:
            return text
        
        try:
            model_info = self.translation_models[source_lang]
            pipeline_translator = model_info['pipeline']
            
            logger.info(f"Metin {source_lang.upper()} -> TR Ã§evriliyor...")
            
            # Uzun metinleri parÃ§alara bÃ¶l
            max_length = 512  # Transformer model limiti
            text_chunks = []
            
            # Metni cÃ¼mlelere bÃ¶l
            sentences = re.split(r'[.!?]+', text)
            
            current_chunk = ""
            for sentence in sentences:
                if len(current_chunk + sentence) < max_length:
                    current_chunk += sentence + ". "
                else:
                    if current_chunk:
                        text_chunks.append(current_chunk.strip())
                    current_chunk = sentence + ". "
            
            if current_chunk:
                text_chunks.append(current_chunk.strip())
            
            # Her parÃ§ayÄ± Ã§evir
            translated_chunks = []
            for i, chunk in enumerate(text_chunks):
                if not chunk.strip():
                    continue
                    
                try:
                    result = pipeline_translator(chunk)
                    if isinstance(result, list) and len(result) > 0:
                        translated_text = result[0]['translation_text']
                    else:
                        translated_text = str(result)
                    
                    translated_chunks.append(translated_text)
                    
                    if i % 10 == 0:  # Her 10 parÃ§ada progress gÃ¶ster
                        logger.info(f"Ã‡eviri ilerlemesi: {i+1}/{len(text_chunks)}")
                        
                except Exception as chunk_error:
                    logger.warning(f"ParÃ§a Ã§evirisi baÅŸarÄ±sÄ±z: {chunk_error}")
                    translated_chunks.append(chunk)  # Ã‡eviremezse orijinali kullan
            
            final_text = ' '.join(translated_chunks)
            logger.info("âœ… Ã‡eviri tamamlandÄ±")
            return final_text
            
        except Exception as e:
            logger.error(f"Ã‡eviri hatasÄ±: {e}")
            return text  # Hata durumunda orijinal metni dÃ¶ndÃ¼r
    
    def get_language_name(self, lang_code: str) -> str:
        """Dil kodunu dil adÄ±na Ã§evir"""
        lang_names = {
            'tr': 'TÃ¼rkÃ§e',
            'en': 'Ä°ngilizce', 
            'de': 'Almanca',
            'fr': 'FransÄ±zca',
            'es': 'Ä°spanyolca',
            'it': 'Ä°talyanca',
            'pt': 'Portekizce',
            'ru': 'RusÃ§a',
            'zh': 'Ã‡ince',
            'ja': 'Japonca',
            'ko': 'Korece',
            'ar': 'ArapÃ§a'
        }
        return lang_names.get(lang_code, f'Bilinmeyen ({lang_code})')

    def extract_text_from_pdf(self, pdf_path: str) -> str:
        """PDF'den metin Ã§Ä±karma"""
        try:
            with open(pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                text = ""
                for page in pdf_reader.pages:
                    text += page.extract_text() + "\n"
                return text
        except Exception as e:
            logger.error(f"PDF okuma hatasÄ±: {e}")
            return ""
    
    def extract_text_from_docx(self, docx_path: str) -> str:
        """DOCX'den metin Ã§Ä±karma"""
        try:
            doc = Document(docx_path)
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            # TablolarÄ± da kontrol et
            for table in doc.tables:
                for row in table.rows:
                    for cell in row.cells:
                        text += cell.text + "\t"
                    text += "\n"
            return text
        except Exception as e:
            logger.error(f"DOCX okuma hatasÄ±: {e}")
            return ""
    
    def extract_text_from_excel(self, excel_path: str) -> str:
        """Excel'den metin Ã§Ä±karma"""
        try:
            # TÃ¼m sheet'leri oku
            xls = pd.ExcelFile(excel_path)
            text = ""
            for sheet_name in xls.sheet_names:
                df = pd.read_excel(excel_path, sheet_name=sheet_name)
                # DataFrame'i string'e Ã§evir
                text += f"Sheet: {sheet_name}\n"
                text += df.to_string() + "\n\n"
            return text
        except Exception as e:
            logger.error(f"Excel okuma hatasÄ±: {e}")
            return ""
    
    def get_file_text(self, file_path: str) -> Tuple[str, str]:
        """Dosya tipine gÃ¶re metin Ã§Ä±karma ve Ã§eviri"""
        file_extension = os.path.splitext(file_path)[1].lower()
        
        # Ã–nce metni Ã§Ä±kar
        original_text = ""
        if file_extension == '.pdf':
            original_text = self.extract_text_from_pdf(file_path)
        elif file_extension in ['.docx', '.doc']:
            original_text = self.extract_text_from_docx(file_path)
        elif file_extension in ['.xlsx', '.xls']:
            original_text = self.extract_text_from_excel(file_path)
        else:
            logger.warning(f"Desteklenmeyen dosya tipi: {file_extension}")
            return "", "unknown"
        
        if not original_text:
            return "", "unknown"
        
        # Dil tespiti
        detected_lang = self.detect_language(original_text)
        
        # Ã‡eviri (gerekirse)
        if detected_lang != 'tr' and len(self.translation_models) > 0:
            translated_text = self.translate_to_turkish(original_text, detected_lang)
            return translated_text, detected_lang
        else:
            return original_text, detected_lang
    
    def normalize_date_string(self, date_str: str) -> str:
        """Tarih string'ini DD/MM/YYYY formatÄ±na Ã§evir"""
        if not date_str or date_str == "BulunamadÄ±":
            return date_str
            
        # Ay isimleri Ã§eviri tablosu
        month_names = {
            # Ä°ngilizce ay isimleri
            'jan': '01', 'january': '01',
            'feb': '02', 'february': '02', 
            'mar': '03', 'march': '03',
            'apr': '04', 'april': '04',
            'may': '05',
            'jun': '06', 'june': '06',
            'jul': '07', 'july': '07',
            'aug': '08', 'august': '08',
            'sep': '09', 'september': '09',
            'oct': '10', 'october': '10',
            'nov': '11', 'november': '11',
            'dec': '12', 'december': '12',
            
            # TÃ¼rkÃ§e ay isimleri
            'ocak': '01',
            'ÅŸubat': '02', 'subat': '02',
            'mart': '03',
            'nisan': '04',
            'mayÄ±s': '05', 'mayis': '05',
            'haziran': '06',
            'temmuz': '07',
            'aÄŸustos': '08', 'agustos': '08',
            'eylÃ¼l': '09', 'eylul': '09',
            'ekim': '10',
            'kasÄ±m': '11', 'kasim': '11',
            'aralÄ±k': '12', 'aralik': '12'
        }
        
        # Ã‡eÅŸitli tarih formatlarÄ±nÄ± normalize et
        date_str = date_str.strip()
        
        # DD/MM/YYYY veya DD.MM.YYYY veya DD-MM-YYYY formatlarÄ±
        if re.match(r'\d{1,2}[./\-]\d{1,2}[./\-]\d{4}', date_str):
            return date_str.replace('.', '/').replace('-', '/')
        
        # YYYY/MM/DD formatÄ±
        if re.match(r'\d{4}[./\-]\d{1,2}[./\-]\d{1,2}', date_str):
            parts = re.split(r'[./\-]', date_str)
            return f"{parts[2].zfill(2)}/{parts[1].zfill(2)}/{parts[0]}"
        
        # DD Month YYYY formatÄ± (Ã¶rn: "18 Apr 2023" veya "18 Nisan 2023")
        month_pattern = r'(\d{1,2})\s+([a-zA-ZÄŸÄ±Ã¼ÅŸÃ§Ã¶ÄIÃœÅÃ‡Ã–]+)\s+(\d{4})'
        match = re.match(month_pattern, date_str, re.IGNORECASE)
        if match:
            day, month_name, year = match.groups()
            month_name_lower = month_name.lower()
            if month_name_lower in month_names:
                month_num = month_names[month_name_lower]
                return f"{day.zfill(2)}/{month_num}/{year}"
        
        # EÄŸer hiÃ§bir format eÅŸleÅŸmezse orijinal string'i dÃ¶ndÃ¼r
        return date_str.replace('.', '/').replace('-', '/')
    
    def check_date_validity(self, text: str, file_path: str = None) -> Tuple[bool, str, str, str]:
        """1 yÄ±l kuralÄ± - Ã–lÃ§Ã¼m tarihi ile rapor tarihi arasÄ±ndaki fark kontrolÃ¼"""
        
        # Ã–lÃ§Ã¼m tarihi arama - Ã§ok kapsamlÄ± pattern'lar
        olcum_patterns = [
            # TÃ¼rkÃ§e formatlar
            r"(?:Ã–lÃ§Ã¼m\s*Tarihi|Test\s*Tarihi|Ã–lÃ§Ã¼m\s*YapÄ±ldÄ±ÄŸÄ±\s*Tarih)\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
            r"(?:Ã–lÃ§Ã¼m|Test).*?(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
            r"(\d{1,2}[./\-]\d{1,2}[./\-]\d{4}).*?(?:Ã¶lÃ§Ã¼m|test)",
            
            # Ä°ngilizce formatlar
            r"(?:Measurement\s*Date|Test\s*Date|Date\s*of\s*(?:Test|Measurement))\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
            r"(?:Measured\s*on|Tested\s*on)\s*[:=]?\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
            r"(\d{1,2}[./\-]\d{1,2}[./\-]\d{4}).*?(?:measurement|test)",
            
            # Genel formatlar
            r"(\d{4}[./\-]\d{1,2}[./\-]\d{1,2})",  # YYYY/MM/DD
            r"(\d{1,2}\s+(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+\d{4})",
            r"(\d{1,2}\s+(?:Ocak|Åubat|Mart|Nisan|MayÄ±s|Haziran|Temmuz|AÄŸustos|EylÃ¼l|Ekim|KasÄ±m|AralÄ±k)\s+\d{4})"
        ]
        
        # Rapor tarihi arama - Ã§ok kapsamlÄ± pattern'lar
        rapor_patterns = [
            # TÃ¼rkÃ§e formatlar
            r"(?:Rapor\s*Tarihi|Belge\s*Tarihi|HazÄ±rlanma\s*Tarihi)\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
            r"(?:Rapor|Belge).*?(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
            r"(?:HazÄ±rlayan|HazÄ±rlandÄ±)\s*[:=]?\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
            
            # Ä°ngilizce formatlar
            r"(?:Report\s*Date|Document\s*Date|Issue\s*Date|Prepared\s*Date)\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
            r"(?:Prepared\s*on|Issued\s*on|Created\s*on)\s*[:=]?\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
            
            # Genel formatlar
            r"(?:Date|Tarih)\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
            r"(\d{4}[./\-]\d{1,2}[./\-]\d{1,2})",  # YYYY/MM/DD
            r"(\d{1,2}\s+(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+\d{4})",
            r"(\d{1,2}\s+(?:Ocak|Åubat|Mart|Nisan|MayÄ±s|Haziran|Temmuz|AÄŸustos|EylÃ¼l|Ekim|KasÄ±m|AralÄ±k)\s+\d{4})"
        ]
        
        olcum_tarihi = None
        rapor_tarihi = None
        
        # Ã–lÃ§Ã¼m tarihini bul
        for pattern in olcum_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                olcum_tarihi = matches[0]
                break
        
        # Rapor tarihini bul
        for pattern in rapor_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                rapor_tarihi = matches[0]
                break
        
        # EÄŸer tarihler bulunamazsa dosya modifikasyon tarihini kullan
        if not rapor_tarihi and file_path and os.path.exists(file_path):
            file_mod_time = datetime.fromtimestamp(os.path.getmtime(file_path))
            rapor_tarihi = file_mod_time.strftime("%d/%m/%Y")
        elif not rapor_tarihi:
            rapor_tarihi = datetime.now().strftime("%d/%m/%Y")
        
        try:
            if olcum_tarihi:
                # Tarih formatlarÄ±nÄ± normalize et ve ay isimlerini Ã§evir
                olcum_tarihi_clean = self.normalize_date_string(olcum_tarihi)
                rapor_tarihi_clean = self.normalize_date_string(rapor_tarihi)
                
                olcum_date = datetime.strptime(olcum_tarihi_clean, '%d/%m/%Y')
                rapor_date = datetime.strptime(rapor_tarihi_clean, '%d/%m/%Y')
                
                # Tarih farkÄ±nÄ± hesapla
                tarih_farki = (rapor_date - olcum_date).days
                
                # 1 yÄ±l (365 gÃ¼n) kontrolÃ¼
                is_valid = tarih_farki <= 365
                
                status_message = f"Ã–lÃ§Ã¼m: {olcum_tarihi_clean}, Rapor: {rapor_tarihi_clean}, Fark: {tarih_farki} gÃ¼n"
                if is_valid:
                    status_message += " (GEÃ‡ERLÄ°)"
                else:
                    status_message += " (GEÃ‡ERSÄ°Z - 1 yÄ±ldan fazla)"
                
                return is_valid, olcum_tarihi_clean, rapor_tarihi_clean, status_message
            else:
                return False, "BulunamadÄ±", rapor_tarihi, "Ã–lÃ§Ã¼m tarihi bulunamadÄ± - RAPOR GEÃ‡ERSÄ°Z"
                
        except ValueError as e:
            logger.error(f"Tarih parse hatasÄ±: {e}")
            return False, olcum_tarihi or "BulunamadÄ±", rapor_tarihi, f"Tarih formatÄ± hatasÄ±: {e}"
    
    def analyze_criteria(self, text: str, category: str) -> Dict[str, GroundingAnalysisResult]:
        """Belirli kategori kriterlerini analiz etme"""
        results = {}
        criteria = self.criteria_details.get(category, {})
        
        for criterion_name, criterion_data in criteria.items():
            pattern = criterion_data["pattern"]
            weight = criterion_data["weight"]
            reverse_logic = criterion_data.get("reverse_logic", False)
            
            matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)
            
            if matches:
                if reverse_logic:
                    # Uygunsuzluk bulundu - dÃ¼ÅŸÃ¼k puan
                    content = f"Uygunsuzluk tespit edildi: {str(matches[:3])}"
                    found = True
                    score = weight // 3  # DÃ¼ÅŸÃ¼k puan
                else:
                    content = str(matches[0]) if len(matches) == 1 else str(matches)
                    found = True
                    score = weight
            else:
                if reverse_logic:
                    # Uygunsuzluk bulunamadÄ± - tam puan (iyi bir ÅŸey)
                    content = "Uygunsuzluk bulunamadÄ± - TÃ¼m Ã¶lÃ§Ã¼mler uygun"
                    found = True
                    score = weight  # Tam puan
                else:
                    # Ä°kincil arama - daha genel pattern
                    general_patterns = {
                        "proje_adi_numarasi": r"(C\d+\.\d+|Proje|Project|SM\s*\d+)",
                        "tesis_bolge_hat": r"(Tesis|Makine|Hat|BÃ¶lge|Line)",
                        "olcum_cihazi": r"(Multimetre|Ohmmetre|Ã–lÃ§Ã¼m|Cihaz)",
                        "kalibrasyon": r"(Kalibrasyon|Kalibre|Cert|Sertifika)",
                        "standartlar": r"(EN\s*60204|IEC\s*60364|Standard|Standart)",
                        "rlo_degeri": r"(\d+[.,]?\d*\s*(?:mÎ©|mohm|ohm))",
                        "uygunluk_durumu": r"(UYGUN|OK|NOK|Uygun|DeÄŸil)",
                        "risk_belirtme": r"(Risk|Tehlike|Uygunsuz|Problem)",
                        "genel_uygunluk": r"(SonuÃ§|Result|Uygun|GeÃ§er|Pass|Fail)"
                    }
                    
                    general_pattern = general_patterns.get(criterion_name)
                    if general_pattern:
                        general_matches = re.findall(general_pattern, text, re.IGNORECASE)
                        if general_matches:
                            content = f"Genel eÅŸleÅŸme bulundu: {general_matches[0]}"
                            found = True
                            score = weight // 2  # KÄ±smi puan
                        else:
                            content = "BulunamadÄ±"
                            found = False
                            score = 0
                    else:
                        content = "BulunamadÄ±"
                        found = False
                        score = 0
            
            results[criterion_name] = GroundingAnalysisResult(
                criteria_name=criterion_name,
                found=found,
                content=content,
                score=score,
                max_score=weight,
                details={"pattern_used": pattern, "matches_found": len(matches) if matches else 0}
            )
        
        return results
    
    def extract_specific_values(self, text: str, file_path: str = None) -> Dict[str, Any]:
        """Spesifik deÄŸerleri Ã§Ä±karma - Dosya adÄ±ndan da bilgi Ã§Ä±kar"""
        values = {}
        
        # Ã–nce dosya adÄ±ndan bilgileri Ã§Ä±kar
        if file_path:
            filename = os.path.basename(file_path)
            
            # Proje numarasÄ± pattern'leri - farklÄ± formatlar iÃ§in
            proje_patterns = [
                r'(C\d{2}\.\d{3})',  # C20.140 formatÄ±
                r'(E\d{2}\.\d{3})',  # E21.207 formatÄ±
                r'(T\d{2,3}[-\.]?\d{3,4})',  # T21-MCC1201 formatÄ±
                r'(\d{4,6})',        # 20092 gibi sayÄ± formatÄ±
                r'([A-Z]\d{2,3}[.-]\d{3,4})'  # Genel format
            ]
            
            # Rapor numarasÄ± pattern'leri
            rapor_patterns = [
                r'SM\s*(\d+)',
                r'MCC(\d+)',
                r'Report\s*No[\s:]*([A-Z0-9.-]+)',
                r'Rapor[\s:]*([A-Z0-9.-]+)'
            ]
            
            # MÃ¼ÅŸteri/firma bilgisi
            musteri_patterns = [
                r'Toyota',
                r'DANONE',
                r'Ford',
                r'BOSCH',
                r'P&G'
            ]
            
            # Dosya adÄ±ndan proje no Ã§Ä±kar
            proje_no = "BulunamadÄ±"
            for pattern in proje_patterns:
                match = re.search(pattern, filename, re.IGNORECASE)
                if match:
                    proje_no = match.group(1)
                    break
            values["proje_no"] = proje_no
            
            # Dosya adÄ±ndan rapor numarasÄ± Ã§Ä±kar
            rapor_no = "BulunamadÄ±"
            for pattern in rapor_patterns:
                match = re.search(pattern, filename, re.IGNORECASE)
                if match:
                    rapor_no = match.group(1)
                    break
            values["rapor_numarasi"] = rapor_no
            
            # MÃ¼ÅŸteri bilgisi
            musteri = "BulunamadÄ±"
            for pattern in musteri_patterns:
                if re.search(pattern, filename, re.IGNORECASE):
                    musteri = pattern
                    break
            values["musteri"] = musteri
            
            # Revizyon bilgisi
            revizyon_match = re.search(r'[vV](\d+)', filename)
            values["revizyon"] = f"v{revizyon_match.group(1)}" if revizyon_match else "v0"
        
        # Ã–nemli deÄŸerler iÃ§in pattern'ler - Ã§ok daha kapsamlÄ±
        value_patterns = {
            # Proje adÄ±/numarasÄ± iÃ§in kapsamlÄ± pattern'ler
            "proje_adi": [
                r"(?:Project\s*Name|Proje\s*Ad[Ä±i])\s*[:=]\s*([^\n\r]+)",
                r"(?:Project\s*No|Proje\s*No|Project\s*Number)\s*[:=]\s*([A-Z0-9.-]+)",
                r"(?:Report\s*Title|Rapor\s*BaÅŸl[Ä±i]ÄŸ[Ä±i])\s*[:=]\s*([^\n\r]+)",
                r"(?:Document\s*Title|Belge\s*BaÅŸl[Ä±i]ÄŸ[Ä±i])\s*[:=]\s*([^\n\r]+)",
                r"(LVD\s+[Ã–Ã¶]lÃ§[Ã¼u]m[^,\n]*)",
                r"(Topraklama\s+S[Ã¼u]reklilik[^,\n]*)",
                r"(Grounding\s+Continuity[^,\n]*)",
                r"([A-Z][a-z]+\s*-\s*[A-Z][a-z]+.*?[Ã–Ã¶]lÃ§[Ã¼u]m)",
                r"(E\d{2}\.\d{3}\s*-[^,\n]+)"
            ],
            
            # Rapor numarasÄ± iÃ§in kapsamlÄ± pattern'ler
            "rapor_numarasi": [
                r"(?:Report\s*No|Rapor\s*No|Report\s*Number)\s*[:=]\s*([A-Z0-9.-]+)",
                r"(?:Document\s*No|Belge\s*No)\s*[:=]\s*([A-Z0-9.-]+)",
                r"(E\d{2}\.\d{3})",
                r"(C\d{2}\.\d{3})",
                r"(T\d{2,3}[-.]?\d{3,4})",
                r"SM\s*(\d+)",
                r"MCC(\d+)",
                r"^\s*([A-Z]\d{2,3}[.-]\d{3,4})"
            ],
            
            # Ã–lÃ§Ã¼m cihazÄ± iÃ§in Ã§ok kapsamlÄ± pattern'ler
            "olcum_cihazi": [
                r"(?:Measuring\s*Instrument|Ã–lÃ§Ã¼m\s*Cihaz[Ä±i]|Test\s*Equipment)\s*[:=]\s*([^\n\r]+)",
                r"(?:Multimeter|Multimetre|Ohmmeter|Ohmmetre)\s*[:=]?\s*([A-Z0-9\s.-]+)",
                r"(?:Instrument|Cihaz)\s*[:=]\s*([^\n\r]+)",
                r"(?:Equipment|Ekipman)\s*[:=]\s*([^\n\r]+)",
                r"(?:Device|Alet)\s*[:=]\s*([^\n\r]+)",
                r"(?:Tester|Test\s*Cihaz[Ä±i])\s*[:=]?\s*([A-Z0-9\s.-]+)",
                r"(Fluke\s*\d+[A-Z]*)",
                r"(Metrix\s*[A-Z0-9]+)",
                r"(Chauvin\s*Arnoux\s*[A-Z0-9]+)",
                r"(Megger\s*[A-Z0-9]+)",
                r"(Hioki\s*[A-Z0-9]+)",
                r"([A-Z][a-z]+\s*\d+[A-Z]*)",  # Genel marka model formatÄ±
                r"(MÎ©\s*metre|mÎ©\s*metre|Loop\s*Tester|Continuity\s*Tester)"
            ],
            
            # Tesis/mÃ¼ÅŸteri bilgisi
            "tesis_adi": [
                r"(?:Customer|MÃ¼ÅŸteri|Client)\s*[:=]\s*([^\n\r]+)",
                r"(?:Facility|Tesis|Plant|Factory)\s*[:=]\s*([^\n\r]+)",
                r"(?:Company|Firma|Corporation)\s*[:=]\s*([^\n\r]+)",
                r"(Toyota[^\n\r]*)",
                r"(DANONE[^\n\r]*)",
                r"(Ford[^\n\r]*)",
                r"(BOSCH[^\n\r]*)",
                r"(?:8X45|8X50|8X9J|9J73)\s*(?:R1|R2|R3)?\s*Hatt[Ä±i]",
                r"([A-Z][a-z]+\s+[A-Z][a-z]+\s+(?:Factory|Plant|Facility))"
            ],
            

            
            # Firma/personel bilgisi
            "firma_personel": [
                r"(?:Prepared\s*by|HazÄ±rlayan|Consultant)\s*[:=]\s*([^\n\r]+)",
                r"(?:Performed\s*by|Ã–lÃ§Ã¼mÃ¼\s*Yapan)\s*[:=]\s*([^\n\r]+)",
                r"(?:Company|Firma)\s*[:=]\s*([^\n\r]+)",
                r"(?:Engineer|MÃ¼hendis)\s*[:=]\s*([^\n\r]+)",
                r"(PILZ[^\n\r]*)",
                r"([A-Z][a-z]+\s+[A-Z][a-z]+\s+(?:Engineering|MÃ¼hendislik))"
            ],
            
            # Tarih pattern'leri - Ã§ok kapsamlÄ±
            "olcum_tarihi": [
                # TÃ¼rkÃ§e formatlar
                r"(?:Ã–lÃ§Ã¼m\s*Tarihi|Test\s*Tarihi|Ã–lÃ§Ã¼m\s*YapÄ±ldÄ±ÄŸÄ±\s*Tarih)\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                r"(?:Ã–lÃ§Ã¼m|Test).*?(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                r"Tarih\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                
                # Ä°ngilizce formatlar
                r"(?:Measurement\s*Date|Test\s*Date|Date\s*of\s*(?:Test|Measurement))\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                r"(?:Measured\s*on|Tested\s*on)\s*[:=]?\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                r"(?:Date|When)\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                
                # Ã‡eÅŸitli formatlar
                r"(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})\s*(?:tarihinde|on|at|de)",
                r"(\d{4}[./\-]\d{1,2}[./\-]\d{1,2})",  # YYYY/MM/DD formatÄ±
                r"(\d{1,2}\s+(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+\d{4})",  # Ä°ngilizce ay isimleri
                r"(\d{1,2}\s+(?:Ocak|Åubat|Mart|Nisan|MayÄ±s|Haziran|Temmuz|AÄŸustos|EylÃ¼l|Ekim|KasÄ±m|AralÄ±k)\s+\d{4})",  # TÃ¼rkÃ§e ay isimleri
                
                # Tablo iÃ§indeki tarihler
                r"(?:Measurement|Ã–lÃ§Ã¼m).*?(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                r"(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",  # Genel tarih formatÄ±
            ],
            
            "rapor_tarihi": [
                # TÃ¼rkÃ§e formatlar
                r"(?:Rapor\s*Tarihi|Belge\s*Tarihi|HazÄ±rlanma\s*Tarihi)\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                r"(?:Rapor|Belge).*?(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                r"(?:HazÄ±rlayan|HazÄ±rlandÄ±)\s*[:=]?\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                
                # Ä°ngilizce formatlar  
                r"(?:Report\s*Date|Document\s*Date|Issue\s*Date|Prepared\s*Date)\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                r"(?:Prepared\s*on|Issued\s*on|Created\s*on)\s*[:=]?\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                r"(?:Report|Document).*?(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                
                # Ã‡eÅŸitli formatlar
                r"(?:Date|Tarih)\s*[:=]\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                r"(\d{4}[./\-]\d{1,2}[./\-]\d{1,2})",  # YYYY/MM/DD formatÄ±
                r"(\d{1,2}\s+(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+\d{4})",  # Ä°ngilizce ay isimleri
                r"(\d{1,2}\s+(?:Ocak|Åubat|Mart|Nisan|MayÄ±s|Haziran|Temmuz|AÄŸustos|EylÃ¼l|Ekim|KasÄ±m|AralÄ±k)\s+\d{4})",  # TÃ¼rkÃ§e ay isimleri
                
                # Tablo baÅŸlÄ±ÄŸÄ± veya footer'daki tarihler
                r"(?:Created|Issued|Published)\s*[:=]?\s*(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",
                r"(\d{1,2}[./\-]\d{1,2}[./\-]\d{4})",  # Genel tarih formatÄ±
            ]
        }
        
        # Metinden deÄŸerleri Ã§Ä±kar - her pattern listesi iÃ§in
        for key, pattern_list in value_patterns.items():
            if key not in values:  # Dosya adÄ±ndan Ã§Ä±karÄ±lmamÄ±ÅŸsa
                found_value = "BulunamadÄ±"
                
                # Pattern listesinde her pattern'i dene
                for pattern in pattern_list:
                    matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)
                    if matches:
                        if isinstance(matches[0], tuple):
                            # Tuple iÃ§indeki boÅŸ olmayan ilk deÄŸeri al
                            value = [m for m in matches[0] if m.strip()]
                            if value:
                                found_value = value[0].strip()
                                break
                        else:
                            found_value = matches[0].strip()
                            break
                
                values[key] = found_value
        
        # Ã–lÃ§Ã¼m verilerini analiz et
        self.analyze_measurement_data(text, values)
        
        return values
    
    def analyze_measurement_data(self, text: str, values: Dict[str, Any]):
        """Ã–lÃ§Ã¼m verilerini analiz et"""
        # RLO deÄŸerlerini topla - daha geniÅŸ pattern
        rlo_patterns = [
            r"(\d+[.,]?\d*)\s*(?:mÎ©|mohm|ohm|Î©)",
            r"(\d+)\s*(?:4x[2-9](?:[.,]\d+)?|4x4)\s*(?:[2-9](?:[.,]\d+)?|4)\s*500",
            r"(\d+)\s*(?:mÎ©|mohm|ohm|Î©)"
        ]
        
        rlo_values = []
        for pattern in rlo_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            for match in matches:
                try:
                    # VirgÃ¼lÃ¼ noktaya Ã§evir ve sayÄ±ya Ã§evir
                    value_str = str(match).replace(',', '.')
                    rlo_values.append(float(value_str))
                except:
                    continue
        
        if rlo_values:
            values["rlo_min"] = f"{min(rlo_values):.1f} mÎ©"
            values["rlo_max"] = f"{max(rlo_values):.1f} mÎ©"
            values["rlo_ortalama"] = f"{sum(rlo_values)/len(rlo_values):.1f} mÎ©"
        else:
            values["rlo_min"] = "BulunamadÄ±"
            values["rlo_max"] = "BulunamadÄ±"
            values["rlo_ortalama"] = "BulunamadÄ±"
        
        # Kesit bilgilerini analiz et - daha geniÅŸ pattern
        kesit_patterns = [
            r"4x4",
            r"4x2[.,]5", 
            r"4x6",
            r"4x10",
            r"YÃ¼k\s*Ä°letken",
            r"Load\s*Conductor",
            r"PE\s*Ä°letken",
            r"PE\s*Conductor"
        ]
        
        total_kesit_count = 0
        for pattern in kesit_patterns:
            count = len(re.findall(pattern, text, re.IGNORECASE))
            total_kesit_count += count
        
        values["toplam_olcum_nokta"] = total_kesit_count
        
        # Uygunluk durumlarÄ±nÄ± say
        uygun_pattern = r"UYGUNUYGUN"
        uygun_matches = re.findall(uygun_pattern, text)
        values["uygun_nokta_sayisi"] = len(uygun_matches)
        
        # Uygunsuz Ã¶lÃ§Ã¼mleri tespit et
        self.find_non_compliant_measurements(text, values)
        
        # Genel sonuÃ§
        if len(uygun_matches) == values["toplam_olcum_nokta"] and values["toplam_olcum_nokta"] > 0:
            values["genel_sonuc"] = "TÃœM NOKTALAR UYGUN"
        else:
            values["genel_sonuc"] = f"{values['toplam_olcum_nokta'] - len(uygun_matches)} NOKTA UYGUNSUZ"
        
        # Hat/bÃ¶lge bilgileri
        hat_pattern = r"(8X45|8X50|8X9J|9J73|8X52|8X60|8X62|8X70)\s*(?:R[1-9])?\s*Hatt[Ä±i]"
        hat_matches = re.findall(hat_pattern, text, re.IGNORECASE)
        if hat_matches:
            unique_hats = list(set(hat_matches))
            values["makine_hatlari"] = ", ".join(unique_hats)
        else:
            values["makine_hatlari"] = "BulunamadÄ±"
    
    def find_non_compliant_measurements(self, text: str, values: Dict[str, Any]):
        """Uygunsuz Ã¶lÃ§Ã¼mleri tespit et"""
        # 500 mÎ©'dan bÃ¼yÃ¼k deÄŸerleri ve D.Y. deÄŸerlerini bul
        lines = text.split('\n')
        non_compliant = []
        
        for i, line in enumerate(lines):
            # SÄ±ra numarasÄ± kontrolÃ¼
            sira_match = re.search(r'(\d+)\s', line)
            if sira_match:
                sira = sira_match.group(1)
                
                # YÃ¼ksek RLO deÄŸeri kontrolÃ¼ (>500 mÎ©) - daha geniÅŸ pattern
                high_rlo_patterns = [
                    r'(\d{3,4})\s*(?:4x[2-9](?:[.,]\d+)?|4x4)\s*(?:[2-9](?:[.,]\d+)?|4)\s*500(\d+)\s*mÎ©\s*<\s*500\s*mÎ©',
                    r'(\d{3,4})\s*(?:mÎ©|mohm|ohm|Î©)',
                    r'(\d{3,4})[.,]?\d*\s*(?:mÎ©|mohm|ohm|Î©)'
                ]
                
                for pattern in high_rlo_patterns:
                    high_rlo_match = re.search(pattern, line, re.IGNORECASE)
                    if high_rlo_match:
                        try:
                            rlo_value = float(str(high_rlo_match.group(1)).replace(',', '.'))
                            if rlo_value > 500:
                                # Hat ve ekipman bilgisi - daha geniÅŸ pattern
                                hat_patterns = [
                                    r'(8X\d+R?\d*)\s*(?:Hatt[Ä±i]|Line|Zone)?\s*(.*?)(?:\s+\d+)',
                                    r'(8X\d+R?\d*)\s*(.*?)(?:\s+\d+)',
                                    r'(Line\s*\d+|Zone\s*\d+)\s*(.*?)(?:\s+\d+)'
                                ]
                                
                                for hat_pattern in hat_patterns:
                                    hat_match = re.search(hat_pattern, line, re.IGNORECASE)
                                    if hat_match:
                                        hat = hat_match.group(1)
                                        ekipman = hat_match.group(2).strip()
                                        non_compliant.append({
                                            'sira': sira,
                                            'rlo': f"{rlo_value:.1f} mÎ©",
                                            'hat': hat,
                                            'ekipman': ekipman,
                                            'durum': 'YÃ¼ksek DirenÃ§'
                                        })
                                        break
                                break
                        except:
                            continue
                
                # D.Y. (DeÄŸer Yok) kontrolÃ¼ - daha geniÅŸ pattern
                if '*D.Y' in line or 'D.Y' in line or 'N/A' in line or 'N/A' in line:
                    hat_patterns = [
                        r'(8X\d+R?\d*)\s*(?:Hatt[Ä±i]|Line|Zone)?\s*(.*?)(?:\s+|$)',
                        r'(8X\d+R?\d*)\s*(.*?)(?:\s+|$)',
                        r'(Line\s*\d+|Zone\s*\d+)\s*(.*?)(?:\s+|$)'
                    ]
                    
                    for hat_pattern in hat_patterns:
                        hat_match = re.search(hat_pattern, line, re.IGNORECASE)
                        if hat_match:
                            hat = hat_match.group(1)
                            ekipman = hat_match.group(2).strip()
                            non_compliant.append({
                                'sira': sira,
                                'rlo': 'D.Y.',
                                'hat': hat,
                                'ekipman': ekipman,
                                'durum': 'Ã–lÃ§Ã¼m YapÄ±lamadÄ±'
                            })
                            break
        
        values["uygunsuz_olcumler"] = non_compliant
    
    def calculate_scores(self, analysis_results: Dict[str, Dict[str, GroundingAnalysisResult]]) -> Dict[str, Any]:
        """PuanlarÄ± hesaplama"""
        category_scores = {}
        total_score = 0
        total_max_score = 100
        
        for category, results in analysis_results.items():
            category_max = self.criteria_weights[category]
            category_earned = sum(result.score for result in results.values())
            category_possible = sum(result.max_score for result in results.values())
            
            # Kategori puanÄ±nÄ± aÄŸÄ±rlÄ±ÄŸa gÃ¶re normalize et
            normalized_score = (category_earned / category_possible * category_max) if category_possible > 0 else 0
            
            category_scores[category] = {
                "earned": category_earned,
                "possible": category_possible,
                "normalized": round(normalized_score, 2),
                "max_weight": category_max,
                "percentage": round((category_earned / category_possible * 100), 2) if category_possible > 0 else 0
            }
            
            total_score += normalized_score
        
        return {
            "category_scores": category_scores,
            "total_score": round(total_score, 2),
            "total_max_score": total_max_score,
            "overall_percentage": round((total_score / total_max_score * 100), 2)
        }
    
    def generate_detailed_report(self, file_path: str) -> Dict[str, Any]:
        """DetaylÄ± rapor oluÅŸturma"""
        logger.info("Topraklama SÃ¼reklilik rapor analizi baÅŸlatÄ±lÄ±yor...")
        
        # Dosyadan metin Ã§Ä±kar ve dil bilgisi al
        text, detected_language = self.get_file_text(file_path)
        if not text:
            return {"error": "Dosya okunamadÄ±"}
        
        # Dil bilgisini logla
        language_name = self.get_language_name(detected_language)
        logger.info(f"ğŸ“– Belge dili: {language_name}")
        if detected_language != 'tr':
            logger.info("ğŸ”„ Ã‡eviri iÅŸlemi tamamlandÄ±")
        
        # Tarih geÃ§erliliÄŸi kontrolÃ¼ (1 yÄ±l kuralÄ±)
        date_valid, olcum_tarihi, rapor_tarihi, date_message = self.check_date_validity(text, file_path)
        
        # Spesifik deÄŸerleri Ã§Ä±kar
        extracted_values = self.extract_specific_values(text, file_path)
        
        # Dil bilgisini extracted_values'a ekle
        extracted_values['detected_language'] = detected_language
        extracted_values['language_name'] = language_name
        
        # Her kategori iÃ§in analiz yap
        analysis_results = {}
        for category in self.criteria_weights.keys():
            analysis_results[category] = self.analyze_criteria(text, category)
        
        # PuanlarÄ± hesapla
        scores = self.calculate_scores(analysis_results)
        
        # Final karar: Tarih geÃ§ersizse puan ne olursa olsun FAILED
        final_status = "PASSED"
        if not date_valid:
            final_status = "FAILED"
            fail_reason = "Ã–lÃ§Ã¼m tarihi ile rapor tarihi arasÄ±ndaki fark 1 yÄ±ldan fazla"
        elif scores["overall_percentage"] < 70:
            final_status = "FAILED"
            fail_reason = f"Toplam puan yetersiz (%{scores['overall_percentage']:.1f} < 70)"
        else:
            fail_reason = None
        
        # Ã–neriler oluÅŸtur
        recommendations = self.generate_recommendations(analysis_results, scores, date_valid)
        
        report = {
            "analiz_tarihi": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "dosya_bilgileri": {
                "file_path": file_path,
                "file_type": os.path.splitext(file_path)[1]
            },
            "tarih_gecerliligi": {
                "gecerli": date_valid,
                "olcum_tarihi": olcum_tarihi,
                "rapor_tarihi": rapor_tarihi,
                "mesaj": date_message
            },
            "cikarilan_degerler": extracted_values,
            "kategori_analizleri": analysis_results,
            "puanlama": scores,
            "oneriler": recommendations,
            "ozet": {
                "toplam_puan": scores["total_score"],
                "yuzde": scores["overall_percentage"],
                "final_durum": final_status,
                "tarih_durumu": "GEÃ‡ERLÄ°" if date_valid else "GEÃ‡ERSÄ°Z",
                "gecme_durumu": "PASSED" if final_status == "PASSED" else "FAILED",
                "fail_nedeni": fail_reason
            }
        }
        
        return report
    
    def generate_recommendations(self, analysis_results: Dict, scores: Dict, date_valid: bool) -> List[str]:
        """Ã–neriler oluÅŸturma"""
        recommendations = []
        
        # Tarih kontrolÃ¼ Ã¶ncelikli
        if not date_valid:
            recommendations.append("ğŸš¨ KRÄ°TÄ°K: Ã–lÃ§Ã¼m tarihi ile rapor tarihi arasÄ±ndaki fark 1 yÄ±ldan fazla - RAPOR GEÃ‡ERSÄ°Z")
            recommendations.append("- Yeni Ã¶lÃ§Ã¼m yapÄ±lmasÄ± gereklidir")
            recommendations.append("- Ã–lÃ§Ã¼m tarihi rapor tarihinden en fazla 1 yÄ±l Ã¶nce olmalÄ±dÄ±r")
        
        # Kategori bazlÄ± Ã¶neriler
        for category, results in analysis_results.items():
            category_score = scores["category_scores"][category]["percentage"]
            
            if category_score < 50:
                recommendations.append(f"âŒ {category} bÃ¶lÃ¼mÃ¼ yetersiz (%{category_score:.1f})")
                
                # Eksik kriterler
                missing_criteria = [name for name, result in results.items() if not result.found]
                if missing_criteria:
                    recommendations.append(f"  Eksik kriterler: {', '.join(missing_criteria)}")
                
                # Kategori Ã¶zel Ã¶neriler
                if category == "Genel Rapor Bilgileri":
                    recommendations.append("  - Proje adÄ± ve numarasÄ± eksiksiz belirtilmelidir")
                    recommendations.append("  - Ã–lÃ§Ã¼m ve rapor tarihleri aÃ§Ä±kÃ§a belirtilmelidir")
                    recommendations.append("  - Rapor numarasÄ± ve revizyon bilgisi eklenmeli")
                
                elif category == "Ã–lÃ§Ã¼m Metodu ve Standart ReferanslarÄ±":
                    recommendations.append("  - Ã–lÃ§Ã¼m cihazÄ± marka/model bilgileri eklenmeli")
                    recommendations.append("  - Kalibrasyon sertifikasÄ± bilgileri verilmeli")
                    recommendations.append("  - EN 60204-1 Tablo 10 referansÄ± yapÄ±lmalÄ±")
                
                elif category == "Ã–lÃ§Ã¼m SonuÃ§ Tablosu":
                    recommendations.append("  - TÃ¼m Ã¶lÃ§Ã¼m noktalarÄ± iÃ§in RLO deÄŸerleri belirtilmeli")
                    recommendations.append("  - YÃ¼k ve PE iletken kesitleri girilmeli")
                    recommendations.append("  - EN 60204 Tablo 10 referans deÄŸerleri eklenmeli")
                    recommendations.append("  - Uygunluk durumu her nokta iÃ§in belirtilmeli")
                
                elif category == "Uygunluk DeÄŸerlendirmesi":
                    recommendations.append("âš ï¸ Uygunsuz noktalar iÃ§in teknik aÃ§Ä±klama ekleyin")
                    recommendations.append("ğŸ“Š Toplam Ã¶lÃ§Ã¼m sayÄ±sÄ± ve uygunluk oranÄ±nÄ± belirtin")
                    recommendations.append("ğŸ” 500 mÎ© limit deÄŸeri aÅŸÄ±mlarÄ±nÄ± iÅŸaretleyin")
                
                elif category == "GÃ¶rsel ve Teknik DÃ¶kÃ¼mantasyon":
                    recommendations.append("  - Ã–lÃ§Ã¼m yapÄ±lan alan fotoÄŸraflarÄ± eklenmeli")
                    recommendations.append("  - Ã–lÃ§Ã¼m cihazÄ± ve baÄŸlantÄ± fotoÄŸraflarÄ± Ã§ekilmeli")
                    recommendations.append("  - Ã–lÃ§Ã¼m noktalarÄ±nÄ±n kroki/ÅŸemasÄ± hazÄ±rlanmalÄ±")
                
                elif category == "SonuÃ§ ve Ã–neriler":
                    recommendations.append("  - Genel uygunluk sonucu aÃ§Ä±kÃ§a belirtilmeli")
                    recommendations.append("  - Standartlara atÄ±f yapÄ±lmalÄ±")
                    recommendations.append("  - Ä°yileÅŸtirme Ã¶nerileri detaylandÄ±rÄ±lmalÄ±")
                    recommendations.append("  - Tekrar Ã¶lÃ§Ã¼m periyodu Ã¶nerilmeli")
            
            elif category_score < 80:
                recommendations.append(f"âš ï¸ {category} bÃ¶lÃ¼mÃ¼ geliÅŸtirilmeli (%{category_score:.1f})")
            
            else:
                recommendations.append(f"âœ… {category} bÃ¶lÃ¼mÃ¼ yeterli (%{category_score:.1f})")
        
        # Genel Ã¶neriler
        if scores["overall_percentage"] < 70:
            recommendations.append("\nğŸš¨ GENEL Ã–NERÄ°LER:")
            recommendations.append("- Rapor EN 60204-1 standardÄ±na tam uyumlu hale getirilmelidir")
            recommendations.append("- IEC 60364 standart referanslarÄ± eklenmeli")
            recommendations.append("- Eksik bilgiler tamamlanmalÄ±dÄ±r")
            recommendations.append("- Ã–lÃ§Ã¼m sonuÃ§larÄ± tablo formatÄ±nda dÃ¼zenlenmeli")
        
        # BaÅŸarÄ±lÄ± durumda
        if scores["overall_percentage"] >= 70 and date_valid:
            recommendations.append("\nâœ… RAPOR BAÅARILI")
            recommendations.append("- TÃ¼m gerekli kriterler saÄŸlanmÄ±ÅŸtÄ±r")
            recommendations.append("- Rapor standarltara uygun olarak hazÄ±rlanmÄ±ÅŸtÄ±r")
        
        return recommendations
    
    def save_report_to_excel(self, report: Dict, output_path: str):
        """Raporu Excel'e kaydetme"""
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            # Ã–zet sayfa
            ozet_data = {
                'Kriter': ['Toplam Puan', 'YÃ¼zde', 'Final Durum', 'Tarih Durumu', 'GeÃ§me Durumu'],
                'DeÄŸer': [
                    report['ozet']['toplam_puan'],
                    f"%{report['ozet']['yuzde']}",
                    report['ozet']['final_durum'],
                    report['ozet']['tarih_durumu'],
                    report['ozet']['gecme_durumu']
                ]
            }
            if report['ozet']['fail_nedeni']:
                ozet_data['Kriter'].append('BaÅŸarÄ±sÄ±zlÄ±k Nedeni')
                ozet_data['DeÄŸer'].append(report['ozet']['fail_nedeni'])
            
            pd.DataFrame(ozet_data).to_excel(writer, sheet_name='Ã–zet', index=False)
            
            # Ã‡Ä±karÄ±lan deÄŸerler
            values_data = []
            for key, value in report['cikarilan_degerler'].items():
                values_data.append({'Kriter': key, 'DeÄŸer': value})
            pd.DataFrame(values_data).to_excel(writer, sheet_name='Ã‡Ä±karÄ±lan DeÄŸerler', index=False)
            
            # Kategori detaylarÄ±
            for category, results in report['kategori_analizleri'].items():
                category_data = []
                for criterion, result in results.items():
                    category_data.append({
                        'Kriter': criterion,
                        'Bulundu': result.found,
                        'Ä°Ã§erik': result.content,
                        'Puan': result.score,
                        'Max Puan': result.max_score
                    })
                
                sheet_name = category[:31]  # Excel sheet name limit
                pd.DataFrame(category_data).to_excel(writer, sheet_name=sheet_name, index=False)
        
        logger.info(f"Rapor Excel dosyasÄ± kaydedildi: {output_path}")
    
    def save_report_to_json(self, report: Dict, output_path: str):
        """Raporu JSON'a kaydetme"""
        # GroundingAnalysisResult objelerini dict'e Ã§evir
        json_report = {}
        for key, value in report.items():
            if key == 'kategori_analizleri':
                json_report[key] = {}
                for category, results in value.items():
                    json_report[key][category] = {}
                    for criterion, result in results.items():
                        json_report[key][category][criterion] = asdict(result)
            else:
                json_report[key] = value
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(json_report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"Rapor JSON dosyasÄ± kaydedildi: {output_path}")

def main():
    """Ana fonksiyon"""
    analyzer = GroundingContinuityReportAnalyzer()
    
    # Dosya yolu - Proje root'undaki belgeyi analiz et
    file_path = "E21.207 - Toyota - Chifong LVD Ã–lÃ§Ã¼m .pdf"
    
    # DosyanÄ±n varlÄ±ÄŸÄ±nÄ± kontrol et
    if not os.path.exists(file_path):
        print(f"âŒ Dosya bulunamadÄ±: {file_path}")
        print("Mevcut dosyalar:")
        for file in os.listdir("."):
            if file.endswith(('.pdf', '.docx', '.xlsx')):
                print(f"  - {file}")
        return
    
    print("âš¡ Topraklama SÃ¼reklilik Rapor Analizi BaÅŸlatÄ±lÄ±yor...")
    print("=" * 60)
    
    # Analizi Ã§alÄ±ÅŸtÄ±r
    report = analyzer.generate_detailed_report(file_path)
    
    if "error" in report:
        print(f"âŒ Hata: {report['error']}")
        return
    
    print("\nğŸ“Š ANALÄ°Z SONUÃ‡LARI")
    print("=" * 60)
    
    print(f"ğŸ“… Analiz Tarihi: {report['analiz_tarihi']}")
    print(f"ğŸ” Tespit Edilen Dil: {report['cikarilan_degerler'].get('language_name', 'Bilinmiyor')}")
    print(f"ğŸ“‹ Toplam Puan: {report['ozet']['toplam_puan']}/100")
    print(f"ğŸ“ˆ YÃ¼zde: %{report['ozet']['yuzde']:.1f}")
    print(f"ğŸ¯ Durum: {report['ozet']['final_durum']}")
    print(f"ğŸ“„ Rapor Tipi: LVD Ã–lÃ§Ã¼m Raporu")
    
    print(f"\nğŸ“… TARÄ°H GEÃ‡ERLÄ°LÄ°ÄÄ°")
    print("-" * 40)
    print(f"Ã–lÃ§Ã¼m Tarihi: {report['tarih_gecerliligi']['olcum_tarihi']}")
    print(f"Rapor Tarihi: {report['tarih_gecerliligi']['rapor_tarihi']}")
    print(f"GeÃ§erlilik: {report['tarih_gecerliligi']['mesaj']}")
    
    print("\nğŸ“‹ Ã–NEMLÄ° Ã‡IKARILAN DEÄERLER")
    print("-" * 40)
    important_values = {
        "proje_no": "Proje No",
        "rapor_numarasi": "Rapor NumarasÄ±", 
        "musteri": "MÃ¼ÅŸteri",
        "proje_adi": "Proje AdÄ±",
        "tesis_adi": "Tesis/Hat",
        "olcum_cihazi": "Ã–lÃ§Ã¼m CihazÄ±",
        "firma_personel": "HazÄ±rlayan Firma",
        "toplam_olcum_nokta": "Toplam Ã–lÃ§Ã¼m NoktasÄ±",
        "uygun_nokta_sayisi": "Uygun Nokta SayÄ±sÄ±",
        "genel_sonuc": "Genel SonuÃ§"
    }
    
    for key, display_name in important_values.items():
        if key in report['cikarilan_degerler']:
            print(f"{display_name}: {report['cikarilan_degerler'][key]}")
    
    print("\nğŸ“Š KATEGORÄ° PUANLARI VE DETAYLAR")
    print("=" * 60)
    
    # Her kategori iÃ§in detaylÄ± analiz
    categories = [
        ("Genel Rapor Bilgileri", "1"),
        ("Ã–lÃ§Ã¼m Metodu ve Standart ReferanslarÄ±", "2"), 
        ("Ã–lÃ§Ã¼m SonuÃ§ Tablosu", "3"),
        ("Uygunluk DeÄŸerlendirmesi", "4"),
        ("GÃ¶rsel ve Teknik DÃ¶kÃ¼mantasyon", "5"),
        ("SonuÃ§ ve Ã–neriler", "6")
    ]
    
    for category, num in categories:
        if category in report['puanlama']['category_scores']:
            score_data = report['puanlama']['category_scores'][category]
            percentage = score_data['percentage']
            print(f"\nğŸ” {category}: {score_data['normalized']:.1f}/{score_data['max_weight']} (%{percentage:.1f})")
            print("-" * 50)
            
            # Bu kategorinin analiz sonuÃ§larÄ±nÄ± gÃ¶ster
            if category in report['kategori_analizleri']:
                category_analysis = report['kategori_analizleri'][category]
                for criterion_name, criterion_result in category_analysis.items():
                    criterion_display = criterion_name.replace('_', ' ').title()
                    if hasattr(criterion_result, 'found') and criterion_result.found:
                        print(f"  âœ… {criterion_display}: {criterion_result.score}/{criterion_result.max_score} puan")
                    else:
                        print(f"  âŒ {criterion_display}: 0/{criterion_result.max_score} puan - BULUNAMADI")
    
    print("\n" + "=" * 60)
    
    print("\nğŸ’¡ Ã–NERÄ°LER VE DEÄERLENDÄ°RME")
    print("-" * 40)
    for recommendation in report['oneriler']:
        print(recommendation)
    
    print("\nğŸ“‹ GENEL DEÄERLENDÄ°RME")
    print("=" * 60)
    
    if report['ozet']['final_durum'] == "PASSED":
        print("âœ… SONUÃ‡: GEÃ‡ERLÄ°")
        print(f"ğŸŒŸ Toplam BaÅŸarÄ±: %{report['ozet']['yuzde']:.1f}")
        print("ğŸ“ DeÄŸerlendirme: Topraklama SÃ¼reklilik raporu genel olarak yeterli kriterleri saÄŸlamaktadÄ±r.")
    else:
        print("âŒ SONUÃ‡: GEÃ‡ERSÄ°Z")
        print(f"âš ï¸ Toplam BaÅŸarÄ±: %{report['ozet']['yuzde']:.1f}")
        print("ğŸ“ DeÄŸerlendirme: Topraklama SÃ¼reklilik raporu minimum gereklilikleri saÄŸlamamaktadÄ±r.")
        
        # BaÅŸarÄ±sÄ±zlÄ±k nedeni varsa yazdÄ±r
        if report['ozet']['fail_nedeni']:
            print(f"ğŸš¨ BaÅŸarÄ±sÄ±zlÄ±k Nedeni: {report['ozet']['fail_nedeni']}")
        
        print("\nâš ï¸ EKSÄ°K GEREKLÄ°LÄ°KLER:")
        for category, results in report['kategori_analizleri'].items():
            missing_items = []
            for criterion, result in results.items():
                if not result.found:
                    missing_items.append(criterion)
            
            if missing_items:
                print(f"\nğŸ” {category}:")
                for item in missing_items[:3]:  # Ä°lk 3 eksik item'Ä± gÃ¶ster
                    readable_name = item.replace('_', ' ').title()
                    print(f"   âŒ {readable_name}")
        
        print("\nğŸ“Œ YAPILMASI GEREKENLER:")
        print("1. Eksik belgelendirmeleri tamamlayÄ±n")
        print("2. Ã–lÃ§Ã¼m cihazÄ± ve kalibrasyon bilgilerini ekleyin")
        print("3. Ã–lÃ§Ã¼m sonuÃ§ tablolarÄ±nÄ± detaylandÄ±rÄ±n")
        print("4. Uygunluk deÄŸerlendirmelerini gÃ¼Ã§lendirin")
        print("5. GÃ¶rsel dokÃ¼mantasyonu artÄ±rÄ±n")
        print("6. Standart referanslarÄ±nÄ± ekleyin")
        
        # Uygunsuz Ã¶lÃ§Ã¼mler varsa ekstra bilgi
        uygunsuz_olcumler = report['cikarilan_degerler'].get('uygunsuz_olcumler', [])
        if uygunsuz_olcumler:
            print("\nğŸš¨ UYGUNSUZ Ã–LÃ‡ÃœMLER:")
            for measurement in uygunsuz_olcumler[:5]:  # Ä°lk 5 uygunsuz Ã¶lÃ§Ã¼mÃ¼ gÃ¶ster
                if measurement['durum'] == 'YÃ¼ksek DirenÃ§':
                    print(f"   âš ï¸ SÄ±ra {measurement['sira']}: {measurement['rlo']} > 500 mÎ©")
                else:
                    print(f"   âš ï¸ SÄ±ra {measurement['sira']}: Ã–lÃ§Ã¼m yapÄ±lamadÄ± (*D.Y.)")
            
            if len(uygunsuz_olcumler) > 5:
                print(f"   ... ve {len(uygunsuz_olcumler) - 5} uygunsuz Ã¶lÃ§Ã¼m daha")

if __name__ == "__main__":
    main()
