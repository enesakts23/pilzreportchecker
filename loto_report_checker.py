import re
import os
import json
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Any
import PyPDF2
from docx import Document
import pandas as pd
from dataclasses import dataclass, asdict
import logging
import pytesseract
from PIL import Image
from pdf2image import convert_from_path

try:
    from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM
    OFFLINE_TRANSLATION_AVAILABLE = True
except ImportError:
    OFFLINE_TRANSLATION_AVAILABLE = False
    print("âš ï¸ Offline Ã§eviri desteÄŸi iÃ§in: pip install transformers torch sentencepiece")

try:
    from langdetect import detect
    LANGUAGE_DETECTION_AVAILABLE = True
except ImportError:
    LANGUAGE_DETECTION_AVAILABLE = False
    print("âš ï¸ Dil tespiti iÃ§in: pip install langdetect")

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class LOTOCriteria:
    """LOTO rapor kriterleri veri sÄ±nÄ±fÄ±"""
    genel_rapor_bilgileri: Dict[str, Any]
    tesis_makine_tanimi: Dict[str, Any]
    loto_politikasi_degerlendirmesi: Dict[str, Any]
    enerji_kaynaklari_analizi: Dict[str, Any]
    izolasyon_noktalari_prosedurler: Dict[str, Any]
    teknik_degerlendirme_sonuclar: Dict[str, Any]
    dokumantasyon_referanslar: Dict[str, Any]

@dataclass
class LOTOAnalysisResult:
    """LOTO analiz sonucu veri sÄ±nÄ±fÄ±"""
    criteria_name: str
    found: bool
    content: str
    score: int
    max_score: int
    details: Dict[str, Any]

class LOTOReportAnalyzer:
    """LOTO rapor analiz sÄ±nÄ±fÄ±"""
    
    def __init__(self):
        # Ã‡eviri Ã¶zelliÄŸini devre dÄ±ÅŸÄ± bÄ±rak (Ã§oÄŸu LOTO raporu TÃ¼rkÃ§e)
        self.translation_models = {}
        self.language_detector = None
        
        # Sadece dil tespiti kullan, Ã§eviri yapma
        logger.info("LOTO analiz sistemi baÅŸlatÄ±lÄ±yor (TÃ¼rkÃ§e optimized)...")
        
        self.criteria_weights = {
            "Genel Rapor Bilgileri": 15,
            "Tesis ve Makine TanÄ±mÄ±": 10,
            "LOTO PolitikasÄ± DeÄŸerlendirmesi": 15,
            "Enerji KaynaklarÄ± Analizi": 20,
            "Ä°zolasyon NoktalarÄ± ve ProsedÃ¼rler": 20,
            "Teknik DeÄŸerlendirme ve SonuÃ§lar": 15,
            "DokÃ¼mantasyon ve Referanslar": 5
        }
        
        self.criteria_details = {
            "Genel Rapor Bilgileri": {
                "proje_adi_belge_no": {"pattern": r"(?:Proje\s*Ad[Ä±i]|Belge\s*(?:No|Numaras[Ä±i])|LOTO|Lockout|Tagout)", "weight": 3},
                "rapor_tarihi": {"pattern": r"(?:Rapor\s*Tarihi|Tarih)\s*[:=]\s*(\d{1,2}[./]\d{1,2}[./]\d{4})", "weight": 3},
                "versiyon_bilgisi": {"pattern": r"(?:Versiyon|Version|Rev\.?|v)\s*[:=]?\s*(\d+|[A-Z])", "weight": 2},
                "revizyon_listesi": {"pattern": r"(?:Revizyon|Revision|DeÄŸiÅŸiklik)\s*(?:Listesi|List|History)", "weight": 2},
                "hazirlayan_firma": {"pattern": r"(?:HazÄ±rlayan|Prepared\s*by|Company|Firma)\s*[:=]\s*([^\n\r]+)", "weight": 3},
                "imza_onay": {"pattern": r"(?:Ä°mza|Signature|Onay|Approval|Ä°nceleyen|Reviewed)", "weight": 2}
            },
            "Tesis ve Makine TanÄ±mÄ±": {
                "tesis_bilgileri": {"pattern": r"(?:Tesis|Facility|Plant|Factory)\s*(?:Ad[Ä±i]|Name)", "weight": 2},
                "makine_tanimi": {"pattern": r"(?:Makine|Machine|Equipment)\s*(?:Tan[Ä±i]m[Ä±i]|Description)", "weight": 2},
                "makine_teknik_bilgi": {"pattern": r"(?:Ãœretici|Manufacturer|Seri\s*No|Serial|Model)", "weight": 2},
                "makine_fotograflari": {"pattern": r"(?:FotoÄŸraf|Photo|Image|GÃ¶rsel|Picture)", "weight": 2},
                "lokasyon_bilgisi": {"pattern": r"(?:Lokasyon|Location|Konum|Position)", "weight": 2}
            },
            "LOTO PolitikasÄ± DeÄŸerlendirmesi": {
                "mevcut_politika": {"pattern": r"(?:Politika|Policy|LOTO\s*Policy|ProsedÃ¼r)", "weight": 4},
                "uygunluk_kontrol": {"pattern": r"(?:Kontrol\s*Listesi|Checklist|Evet|HayÄ±r|Yes|No)", "weight": 3},
                "prosedur_degerlendirme": {"pattern": r"(?:ProsedÃ¼r|Procedure|DeÄŸerlendirme|Assessment)", "weight": 3},
                "personel_gorusme": {"pattern": r"(?:Personel|Personnel|GÃ¶rÃ¼ÅŸme|Interview|Ã‡alÄ±ÅŸan)", "weight": 3},
                "egitim_durumu": {"pattern": r"(?:EÄŸitim|Training|Education|Kurs|Course)", "weight": 2}
            },
            "Enerji KaynaklarÄ± Analizi": {
                "enerji_kaynagi_tanimlama": {"pattern": r"(?:Enerji\s*KaynaÄŸ[Ä±i]|Energy\s*Source|Elektrik|Electric|Pn[Ã¶o]matik|Pneumatic|Hidrolik|Hydraulic)", "weight": 5},
                "izolasyon_cihazi": {"pattern": r"(?:Ä°zolasyon|Isolation|Disconnection|Switch|Valve|Vana)", "weight": 4},
                "cihaz_durumu": {"pattern": r"(?:Durum|Status|Ã‡alÄ±ÅŸ[Ä±t][Ä±a]r|Working|Kilitlen|Lock)", "weight": 4},
                "kilitleme_ekipmanlari": {"pattern": r"(?:Kilit|Lock|Etiket|Tag|Valf\s*Kit|Valve\s*Lock)", "weight": 4},
                "uygunsuz_enerji": {"pattern": r"(?:Uygunsuz|Unsuitable|Risk|Tehlike|Hazard)", "weight": 3}
            },
            "Ä°zolasyon NoktalarÄ± ve ProsedÃ¼rler": {
                "izolasyon_noktalari": {"pattern": r"(?:Ä°zolasyon\s*Nokta|Isolation\s*Point|Kesme\s*Nokta)", "weight": 5},
                "prosedur_detaylari": {"pattern": r"(?:ProsedÃ¼r\s*Detay|Procedure\s*Detail|Ad[Ä±i]m|Step)", "weight": 4},
                "mevcut_prosedur": {"pattern": r"(?:Mevcut\s*ProsedÃ¼r|Current\s*Procedure|Existing)", "weight": 4},
                "tavsiyeler": {"pattern": r"(?:Tavsiye|Recommendation|Ã–neri|Suggestion|Ä°yileÅŸtirme)", "weight": 4},
                "cihaz_fotograflari": {"pattern": r"(?:Cihaz.*FotoÄŸraf|Equipment.*Photo|GÃ¶rsel.*DokÃ¼mantasyon)", "weight": 3}
            },
            "Teknik DeÄŸerlendirme ve SonuÃ§lar": {
                "kabul_edilebilirlik": {"pattern": r"(?:Kabul\s*Edilebilir|Acceptable|Uygun|Suitable|EVET|YES|HAYIR|NO)", "weight": 4},
                "bulgular_yorumlar": {"pattern": r"(?:Bulgu|Finding|Yorum|Comment|Tespit|Detection)", "weight": 3},
                "sonuc_tablolari": {"pattern": r"(?:SonuÃ§\s*Tablo|Result\s*Table|Ã–zet|Summary)", "weight": 3},
                "oneriler": {"pattern": r"(?:Ã–neri|Recommendation|Ä°yileÅŸtirme|Improvement)", "weight": 3},
                "mevzuat_uygunluk": {"pattern": r"(?:2006/42|2009/104|Direktif|Directive|EC|EN\s*ISO)", "weight": 2}
            },
            "DokÃ¼mantasyon ve Referanslar": {
                "terminoloji": {"pattern": r"(?:Terminoloji|Terminology|Tan[Ä±i]m|Definition)", "weight": 1},
                "kisaltmalar": {"pattern": r"(?:K[Ä±i]saltma|Abbreviation|Acronym)", "weight": 1},
                "mevzuat_referans": {"pattern": r"(?:Mevzuat|Legislation|Direktif|Directive|2006/42|2009/104)", "weight": 1},
                "normatif_referans": {"pattern": r"(?:EN\s*ISO\s*12100|EN\s*ISO\s*60204|EN\s*ISO\s*4414|EN\s*ISO\s*14118)", "weight": 1},
                "metodoloji": {"pattern": r"(?:Metodoloji|Methodology|YÃ¶ntem|Method|YaklaÅŸ[Ä±i]m)", "weight": 1}
            }
        }
    
    def init_translation_models(self):
        """Offline Ã§eviri modellerini baÅŸlat"""
        try:
            logger.info("Offline Ã§eviri modelleri yÃ¼kleniyor...")
            
            # Facebook NLLB modeli - daha kÃ¼Ã§Ã¼k ve hÄ±zlÄ±
            model_name = "facebook/nllb-200-distilled-600M"
            
            try:
                logger.info("NLLB Ã§eviri modeli kontrol ediliyor...")
                tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir="./models")
                model = AutoModelForSeq2SeqLM.from_pretrained(model_name, cache_dir="./models")
                
                # NLLB iÃ§in pipeline oluÅŸtur
                translator = pipeline('translation', 
                                    model=model, 
                                    tokenizer=tokenizer,
                                    device=-1)
                
                self.translation_models['nllb'] = {
                    'tokenizer': tokenizer,
                    'model': model,
                    'pipeline': translator
                }
                logger.info("âœ… NLLB Ã§eviri modeli hazÄ±r (200+ dil destekli)")
                
            except Exception as e:
                logger.warning(f"âš ï¸ NLLB modeli yÃ¼klenemedi: {str(e)[:100]}...")
                logger.info("Alternatif olarak Google Translate API'si kullanÄ±labilir")
                
            if len(self.translation_models) > 0:
                logger.info(f"Ã‡eviri sistemi aktif")
            else:
                logger.info("Ã‡eviri modelleri yÃ¼klenemedi, sadece TÃ¼rkÃ§e desteklenecek")
                
        except Exception as e:
            logger.error(f"Ã‡eviri modelleri baÅŸlatÄ±lamadÄ±: {e}")
            logger.info("Ã‡eviri Ã¶zelliÄŸi devre dÄ±ÅŸÄ±, sadece TÃ¼rkÃ§e desteklenecek")
    
    def detect_language(self, text: str) -> str:
        """Metin dilini tespit et"""
        if not LANGUAGE_DETECTION_AVAILABLE:
            return 'tr'
        
        try:
            sample_text = text[:500].strip()
            if not sample_text:
                return 'tr'
                
            detected_lang = detect(sample_text)
            logger.info(f"Tespit edilen dil: {detected_lang}")
            return detected_lang
            
        except Exception as e:
            logger.warning(f"Dil tespiti baÅŸarÄ±sÄ±z: {e}")
            return 'tr'
    
    def translate_to_turkish(self, text: str, source_lang: str) -> str:
        """Metni TÃ¼rkÃ§e'ye Ã§evir - ÅŸimdilik devre dÄ±ÅŸÄ±"""
        if source_lang != 'tr':
            logger.info(f"Tespit edilen dil: {source_lang.upper()} - Ã‡eviri yapÄ±lmÄ±yor, orijinal metin kullanÄ±lÄ±yor")
        return text
    
    def extract_text_from_pdf(self, pdf_path: str) -> str:
        """PDF'den metin Ã§Ä±karma - PyPDF2 ve OCR ile"""
        try:
            with open(pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                text = ""
                for page in pdf_reader.pages:
                    page_text = page.extract_text()
                    page_text = re.sub(r'\s+', ' ', page_text)
                    page_text = page_text.replace('|', ' ')
                    text += page_text + "\n"
                
                text = text.replace('â€”', '-')
                text = text.replace('"', '"').replace('"', '"')
                text = text.replace('Â´', "'")
                text = re.sub(r'[^\x00-\x7F\u00C0-\u00FF\u0100-\u017F\u0180-\u024F]+', ' ', text)
                text = text.strip()
                
                if len(text) > 50:
                    logger.info("Metin PyPDF2 ile Ã§Ä±karÄ±ldÄ±")
                    return text
                
                logger.info("PyPDF2 ile yeterli metin bulunamadÄ±, OCR deneniyor...")
                return self.extract_text_with_ocr(pdf_path)
                
        except Exception as e:
            logger.error(f"PDF metin Ã§Ä±karma hatasÄ±: {e}")
            logger.info("OCR'a geÃ§iliyor...")
            return self.extract_text_with_ocr(pdf_path)

    def extract_text_with_ocr(self, pdf_path: str) -> str:
        """OCR ile metin Ã§Ä±karma"""
        try:
            images = convert_from_path(pdf_path, dpi=300)
            
            all_text = ""
            for i, image in enumerate(images):
                try:
                    text = pytesseract.image_to_string(image, lang='tur+eng')
                    text = re.sub(r'\s+', ' ', text)
                    text = text.replace('|', ' ')
                    all_text += text + "\n"
                    
                    logger.info(f"OCR ile sayfa {i+1}'den {len(text)} karakter Ã§Ä±karÄ±ldÄ±")
                    
                except Exception as page_error:
                    logger.error(f"Sayfa {i+1} OCR hatasÄ±: {page_error}")
                    continue
            
            all_text = all_text.replace('â€”', '-')
            all_text = all_text.replace('"', '"').replace('"', '"')
            all_text = all_text.replace('Â´', "'")
            all_text = re.sub(r'[^\x00-\x7F\u00C0-\u00FF\u0100-\u017F\u0180-\u024F]+', ' ', all_text)
            all_text = all_text.strip()
            
            logger.info(f"OCR toplam metin uzunluÄŸu: {len(all_text)}")
            return all_text
            
        except Exception as e:
            logger.error(f"OCR metin Ã§Ä±karma hatasÄ±: {e}")
            return ""
    
    def analyze_criteria(self, text: str, category: str) -> Dict[str, LOTOAnalysisResult]:
        """Kriterleri analiz et"""
        results = {}
        criteria = self.criteria_details.get(category, {})
        
        for criterion_name, criterion_data in criteria.items():
            pattern = criterion_data["pattern"]
            weight = criterion_data["weight"]
            
            matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)
            
            if matches:
                content = f"Bulunan: {str(matches[:3])}"
                found = True
                score = min(weight, len(matches) * (weight // 2))
                score = max(score, weight // 2)
            else:
                content = "BulunamadÄ±"
                found = False
                score = 0
            
            results[criterion_name] = LOTOAnalysisResult(
                criteria_name=criterion_name,
                found=found,
                content=content,
                score=score,
                max_score=weight,
                details={
                    "pattern_used": pattern,
                    "matches_count": len(matches) if matches else 0
                }
            )
        
        return results

    def check_date_validity(self, text: str) -> Dict[str, Any]:
        """Rapor tarih geÃ§erliliÄŸini kontrol et"""
        date_patterns = [
            r"(?:Rapor\s*Tarihi)\s*[:=]?\s*(\d{1,2})[./](\d{1,2})[./](\d{4})",
            r"(?:Report\s*Date)\s*[:=]?\s*(\d{1,2})[./](\d{1,2})[./](\d{4})",
            r"(?:Tarih)\s*[:=]?\s*(\d{1,2})[./](\d{1,2})[./](\d{4})",
            r"(\d{1,2})[./](\d{1,2})[./](\d{4})",
            r"(\d{4})[./](\d{1,2})[./](\d{1,2})"
        ]
        
        for pattern in date_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            for match in matches:
                try:
                    if len(str(match[2])) == 4:  # DD/MM/YYYY format
                        day, month, year = int(match[0]), int(match[1]), int(match[2])
                    else:  # YYYY/MM/DD format
                        year, month, day = int(match[0]), int(match[1]), int(match[2])
                    
                    if 1 <= day <= 31 and 1 <= month <= 12 and 2020 <= year <= 2030:
                        report_date = datetime(year, month, day)
                        current_date = datetime.now()
                        date_diff = current_date - report_date
                        
                        is_valid = date_diff.days <= 365
                        
                        return {
                            "found": True,
                            "report_date": report_date.strftime("%d.%m.%Y"),
                            "days_old": date_diff.days,
                            "is_valid": is_valid,
                            "validity_reason": "1 yÄ±ldan eski deÄŸil" if is_valid else "1 yÄ±ldan eski - GEÃ‡ERSÄ°Z"
                        }
                except:
                    continue
        
        return {
            "found": False,
            "report_date": "BulunamadÄ±",
            "days_old": 0,
            "is_valid": False,
            "validity_reason": "Rapor tarihi bulunamadÄ±"
        }

    def calculate_scores(self, analysis_results: Dict[str, Dict[str, LOTOAnalysisResult]]) -> Dict[str, Any]:
        """PuanlarÄ± hesapla"""
        category_scores = {}
        total_score = 0
        
        for category, results in analysis_results.items():
            category_max = self.criteria_weights[category]
            category_earned = sum(result.score for result in results.values())
            category_possible = sum(result.max_score for result in results.values())
            
            if category_possible > 0:
                percentage = (category_earned / category_possible) * 100
                normalized_score = (percentage / 100) * category_max
            else:
                percentage = 0
                normalized_score = 0
            
            category_scores[category] = {
                "earned": category_earned,
                "possible": category_possible,
                "normalized": round(normalized_score, 2),
                "max_weight": category_max,
                "percentage": round(percentage, 2)
            }
            
            total_score += normalized_score
        
        return {
            "category_scores": category_scores,
            "total_score": round(total_score, 2),
            "percentage": round(total_score, 2)
        }

    def extract_specific_values(self, text: str) -> Dict[str, Any]:
        """Spesifik deÄŸerleri Ã§Ä±kar"""
        values = {
            "proje_adi": "BulunamadÄ±",
            "rapor_tarihi": "BulunamadÄ±",
            "hazirlayan_firma": "BulunamadÄ±",
            "kabul_durumu": "BulunamadÄ±"
        }
        
        # Proje adÄ± iÃ§in daha geniÅŸ pattern'lar
        project_patterns = [
            r"(?:Proje\s*Ad[Ä±i])\s*[:=]\s*([^\n\r]+)",
            r"(?:Project\s*Name)\s*[:=]\s*([^\n\r]+)",
            r"LOTO.*?([A-Z][A-Za-z\s]+)",
            r"Lockout.*?Tagout.*?([A-Z][A-Za-z\s]+)"
        ]
        
        for pattern in project_patterns:
            project_match = re.search(pattern, text, re.IGNORECASE)
            if project_match:
                values["proje_adi"] = project_match.group(1).strip()[:50]
                break
        
        # Rapor tarihi iÃ§in daha geniÅŸ pattern'lar
        date_patterns = [
            r"(?:Rapor\s*Tarihi)\s*[:=]?\s*(\d{1,2}[./]\d{1,2}[./]\d{4})",
            r"(?:Report\s*Date)\s*[:=]?\s*(\d{1,2}[./]\d{1,2}[./]\d{4})",
            r"(?:Tarih)\s*[:=]?\s*(\d{1,2}[./]\d{1,2}[./]\d{4})",
            r"(\d{1,2}[./]\d{1,2}[./]\d{4})",
            r"(\d{4}[./]\d{1,2}[./]\d{1,2})"
        ]
        
        for pattern in date_patterns:
            date_match = re.search(pattern, text, re.IGNORECASE)
            if date_match:
                values["rapor_tarihi"] = date_match.group(1)
                break
        
        # HazÄ±rlayan firma iÃ§in daha geniÅŸ pattern'lar
        company_patterns = [
            r"(?:Raporu\s*HazÄ±rlayan)\s*[:=]?\s*([^\n\r]+)",
            r"(?:HazÄ±rlayan)\s*[:=]?\s*([^\n\r]+)",
            r"(?:Prepared\s*by)\s*[:=]?\s*([^\n\r]+)",
            r"(?:Company)\s*[:=]?\s*([^\n\r]+)",
            r"(?:Firma)\s*[:=]?\s*([^\n\r]+)",
            r"PILZ\s+MAKÄ°NE\s+EMNÄ°YET\s+OTOMASYON",
            r"PILZ.*?OTOMASYON",
            r"(?:Prepared|HazÄ±rlayan).*?(PILZ[^\n\r]*)",
            r"(PILZ\s+[A-Z\s]+OTOMASYON)"
        ]
        
        for pattern in company_patterns:
            company_match = re.search(pattern, text, re.IGNORECASE)
            if company_match:
                if len(company_match.groups()) > 0:
                    values["hazirlayan_firma"] = company_match.group(1).strip()[:50]
                else:
                    values["hazirlayan_firma"] = company_match.group().strip()[:50]
                break
        
        # Kabul durumu iÃ§in pattern'lar
        acceptance_patterns = [
            r"(?:Kabul\s*Edilebilir|Acceptable)\s*[:=]?\s*(EVET|YES|HAYIR|NO)",
            r"(UYGUN|UYGUNSUZ|SUITABLE|UNSUITABLE)",
            r"(PASS|FAIL|GEÃ‡ERLÄ°|GEÃ‡ERSÄ°Z)"
        ]
        
        for pattern in acceptance_patterns:
            acceptance_match = re.search(pattern, text, re.IGNORECASE)
            if acceptance_match:
                values["kabul_durumu"] = acceptance_match.group(1).upper()
                break
        
        return values

    def generate_recommendations(self, analysis_results: Dict, scores: Dict, date_validity: Dict) -> List[str]:
        """Ã–neriler oluÅŸtur"""
        recommendations = []
        
        if not date_validity["is_valid"]:
            recommendations.append("ğŸš¨ KRÄ°TÄ°K: Rapor tarihi 1 yÄ±ldan eski - Rapor GEÃ‡ERSÄ°Z")
            recommendations.append(f"ğŸ“… Rapor tarihi: {date_validity['report_date']} ({date_validity['days_old']} gÃ¼n eski)")
            return recommendations
        
        total_percentage = scores["percentage"]
        
        if total_percentage >= 70:
            recommendations.append(f"âœ… LOTO Raporu GEÃ‡ERLÄ° (Toplam: %{total_percentage:.1f})")
        else:
            recommendations.append(f"âŒ LOTO Raporu GEÃ‡ERSÄ°Z (Toplam: %{total_percentage:.1f})")
        
        for category, results in analysis_results.items():
            category_score = scores["category_scores"][category]["percentage"]
            
            if category_score < 40:
                recommendations.append(f"ğŸ”´ {category} bÃ¶lÃ¼mÃ¼ yetersiz (%{category_score:.1f})")
                missing_items = [name for name, result in results.items() if not result.found]
                if missing_items:
                    recommendations.append(f"   Eksik: {', '.join(missing_items[:3])}")
            elif category_score < 70:
                recommendations.append(f"ğŸŸ¡ {category} bÃ¶lÃ¼mÃ¼ geliÅŸtirilmeli (%{category_score:.1f})")
            else:
                recommendations.append(f"ğŸŸ¢ {category} bÃ¶lÃ¼mÃ¼ yeterli (%{category_score:.1f})")
        
        if total_percentage < 70:
            recommendations.extend([
                "",
                "ğŸ’¡ Ä°YÄ°LEÅTÄ°RME Ã–NERÄ°LERÄ°:",
                "- Enerji kaynaklarÄ± detaylÄ± tanÄ±mlanmalÄ±",
                "- Ä°zolasyon noktalarÄ± eksiksiz belirtilmeli",
                "- LOTO prosedÃ¼rÃ¼ adÄ±mlarÄ± detaylandÄ±rÄ±lmalÄ±",
                "- Teknik deÄŸerlendirme ve sonuÃ§lar gÃ¼Ã§lendirilmeli",
                "- GÃ¶rsel dokÃ¼mantasyon artÄ±rÄ±lmalÄ±"
            ])
        
        return recommendations

    def analyze_loto_report(self, pdf_path: str) -> Dict[str, Any]:
        """Ana LOTO rapor analiz fonksiyonu"""
        logger.info("LOTO rapor analizi baÅŸlatÄ±lÄ±yor...")
        
        if not os.path.exists(pdf_path):
            return {"error": f"PDF dosyasÄ± bulunamadÄ±: {pdf_path}"}
        
        text = self.extract_text_from_pdf(pdf_path)
        if not text:
            return {"error": "PDF'den metin Ã§Ä±karÄ±lamadÄ±"}
        
        detected_lang = self.detect_language(text)
        
        if detected_lang != 'tr' and detected_lang in self.translation_models:
            logger.info(f"{detected_lang.upper()} dilinden TÃ¼rkÃ§e'ye Ã§eviriliyor...")
            text = self.translate_to_turkish(text, detected_lang)
        
        date_validity = self.check_date_validity(text)
        
        analysis_results = {}
        for category in self.criteria_weights.keys():
            analysis_results[category] = self.analyze_criteria(text, category)
        
        scores = self.calculate_scores(analysis_results)
        extracted_values = self.extract_specific_values(text)
        recommendations = self.generate_recommendations(analysis_results, scores, date_validity)
        
        final_status = "PASS" if date_validity["is_valid"] and scores["percentage"] >= 70 else "FAIL"
        
        report = {
            "analiz_tarihi": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "dosya_bilgisi": {
                "pdf_path": pdf_path,
                "detected_language": detected_lang
            },
            "tarih_gecerliligi": date_validity,
            "cikarilan_degerler": extracted_values,
            "kategori_analizleri": analysis_results,
            "puanlama": scores,
            "oneriler": recommendations,
            "ozet": {
                "toplam_puan": scores["total_score"],
                "yuzde": scores["percentage"],
                "durum": final_status,
                "rapor_tipi": "LOTO"
            }
        }
        
        return report

    def save_report_to_excel(self, report: Dict, output_path: str):
        """Raporu Excel'e kaydet"""
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            summary_data = {
                'Kriter': ['Toplam Puan', 'YÃ¼zde', 'Durum', 'Rapor Tipi', 'Tarih GeÃ§erliliÄŸi'],
                'DeÄŸer': [
                    report['ozet']['toplam_puan'],
                    f"%{report['ozet']['yuzde']}",
                    report['ozet']['durum'],
                    report['ozet']['rapor_tipi'],
                    "GeÃ§erli" if report['tarih_gecerliligi']['is_valid'] else "GeÃ§ersiz"
                ]
            }
            pd.DataFrame(summary_data).to_excel(writer, sheet_name='Ã–zet', index=False)
            
            values_data = []
            for key, value in report['cikarilan_degerler'].items():
                values_data.append({'Kriter': key, 'DeÄŸer': str(value)})
            pd.DataFrame(values_data).to_excel(writer, sheet_name='Ã‡Ä±karÄ±lan_DeÄŸerler', index=False)
            
            for category, results in report['kategori_analizleri'].items():
                category_data = []
                for criterion, result in results.items():
                    category_data.append({
                        'Kriter': criterion,
                        'Bulundu': result.found,
                        'Ä°Ã§erik': result.content,
                        'Puan': result.score,
                        'Maksimum Puan': result.max_score
                    })
                sheet_name = category.replace('/', '_').replace('\\', '_')[:31]
                pd.DataFrame(category_data).to_excel(writer, sheet_name=sheet_name, index=False)

        logger.info(f"Rapor Excel'e kaydedildi: {output_path}")

    def save_report_to_json(self, report: Dict, output_path: str):
        """Raporu JSON'a kaydet"""
        json_report = {}
        for key, value in report.items():
            if key == 'kategori_analizleri':
                json_report[key] = {}
                for category, results in value.items():
                    json_report[key][category] = {}
                    for criterion, result in results.items():
                        json_report[key][category][criterion] = asdict(result)
            else:
                json_report[key] = value

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(json_report, f, ensure_ascii=False, indent=2)

        logger.info(f"Rapor JSON'a kaydedildi: {output_path}")

def main():
    """Ana fonksiyon"""
    analyzer = LOTOReportAnalyzer()

    pdf_path = "lotoreport2.pdf"

    if not os.path.exists(pdf_path):
        print(f"âŒ PDF dosyasÄ± bulunamadÄ±: {pdf_path}")
        return
    
    print("ğŸ”’ LOTO Rapor Analizi BaÅŸlatÄ±lÄ±yor...")
    print("=" * 60)
    
    report = analyzer.analyze_loto_report(pdf_path)
    
    if "error" in report:
        print(f"âŒ Hata: {report['error']}")
        return
    
    print("\nğŸ“Š ANALÄ°Z SONUÃ‡LARI")
    print("=" * 60)
    
    print(f"ğŸ“… Analiz Tarihi: {report['analiz_tarihi']}")
    print(f"ğŸ” Tespit Edilen Dil: {report['dosya_bilgisi']['detected_language'].upper()}")
    print(f"ğŸ“‹ Toplam Puan: {report['ozet']['toplam_puan']}/100")
    print(f"ğŸ“ˆ YÃ¼zde: %{report['ozet']['yuzde']}")
    print(f"ğŸ¯ Durum: {report['ozet']['durum']}")
    print(f"ğŸ“„ Rapor Tipi: {report['ozet']['rapor_tipi']}")
    
    print(f"\nğŸ“… TARÄ°H GEÃ‡ERLÄ°LÄ°ÄÄ°")
    print("-" * 40)
    date_info = report['tarih_gecerliligi']
    print(f"Rapor Tarihi: {date_info['report_date']}")
    print(f"YaÅŸ: {date_info['days_old']} gÃ¼n")
    print(f"GeÃ§erlilik: {date_info['validity_reason']}")
    
    print("\nğŸ“‹ Ã–NEMLÄ° Ã‡IKARILAN DEÄERLER")
    print("-" * 40)
    for key, value in report['cikarilan_degerler'].items():
        display_name = {
            "proje_adi": "Proje AdÄ±",
            "rapor_tarihi": "Rapor Tarihi", 
            "hazirlayan_firma": "HazÄ±rlayan Firma",
            "kabul_durumu": "Kabul Durumu"
        }.get(key, key.replace('_', ' ').title())
        print(f"{display_name}: {value}")
    
    print("\nğŸ“Š KATEGORÄ° PUANLARI")
    print("-" * 40)
    for category, score_data in report['puanlama']['category_scores'].items():
        print(f"{category}: {score_data['normalized']}/{score_data['max_weight']} (%{score_data['percentage']:.1f})")
    
    print("\nğŸ’¡ Ã–NERÄ°LER VE DEÄERLENDÄ°RME")
    print("-" * 40)
    for recommendation in report['oneriler']:
        print(recommendation)
    
    print("\nğŸ“‹ GENEL DEÄERLENDÄ°RME")
    print("=" * 60)
    
    if not report['tarih_gecerliligi']['is_valid']:
        print("âŒ SONUÃ‡: GEÃ‡ERSÄ°Z")
        print(f"ğŸš¨ KRÄ°TÄ°K: Rapor tarihi 1 yÄ±ldan eski ({report['tarih_gecerliligi']['days_old']} gÃ¼n)")
        print("ğŸ“ DeÄŸerlendirme: Tarih geÃ§erliliÄŸi nedeniyle rapor kabul edilemez.")
    elif report['ozet']['yuzde'] >= 70:
        print("âœ… SONUÃ‡: GEÃ‡ERLÄ°")
        print(f"ğŸŒŸ Toplam BaÅŸarÄ±: %{report['ozet']['yuzde']:.1f}")
        print("ğŸ“ DeÄŸerlendirme: LOTO raporu genel olarak yeterli kriterleri saÄŸlamaktadÄ±r.")
    else:
        print("âŒ SONUÃ‡: GEÃ‡ERSÄ°Z")
        print(f"âš ï¸ Toplam BaÅŸarÄ±: %{report['ozet']['yuzde']:.1f}")
        print("ğŸ“ DeÄŸerlendirme: LOTO raporu minimum gereklilikleri saÄŸlamamaktadÄ±r.")
        
        print("\nâš ï¸ EKSÄ°K GEREKLÄ°LÄ°KLER:")
        for category, results in report['kategori_analizleri'].items():
            missing_items = []
            for criterion, result in results.items():
                if not result.found:
                    missing_items.append(criterion)
            
            if missing_items:
                print(f"\nğŸ” {category}:")
                for item in missing_items:
                    readable_name = item.replace('_', ' ').title()
                    print(f"   âŒ {readable_name}")
        
        print("\nğŸ“Œ YAPILMASI GEREKENLER:")
        print("1. Eksik belgelendirmeleri tamamlayÄ±n")
        print("2. Enerji kaynaklarÄ± ve izolasyon noktalarÄ±nÄ± detaylandÄ±rÄ±n")
        print("3. LOTO prosedÃ¼rlerini eksiksiz tanÄ±mlayÄ±n")
        print("4. Teknik deÄŸerlendirme ve sonuÃ§larÄ± gÃ¼Ã§lendirin")
        print("5. GÃ¶rsel dokÃ¼mantasyonu artÄ±rÄ±n")
        print("6. Mevzuat referanslarÄ±nÄ± ekleyin")

if __name__ == "__main__":
    main()
